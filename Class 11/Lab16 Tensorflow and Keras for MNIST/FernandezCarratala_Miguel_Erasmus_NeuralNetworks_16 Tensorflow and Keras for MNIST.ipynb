{"nbformat":4,"nbformat_minor":0,"metadata":{"celltoolbar":"Create Assignment","kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"FernandezCarratala_Miguel_Erasmus_NeuralNetworks_16 Tensorflow and Keras for MNIST.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-0b2104075deb75b5","locked":true,"schema_version":1,"solution":false},"id":"fD841UmBUcoF","colab_type":"text"},"source":["# Erasmus Neural Networks\n","http://michalbereta.pl/nn\n","## TensorFlow and Keras for MNIST\n","\n","\n","Keras: https://keras.io/\n","\n","TensorFlow: https://www.tensorflow.org/\n","\n","### Note !\n","\n","Training exemplary neural networks in this notebook is computationally demanding. In case of problems, use the attached pretrained models  (files \\*.hdf5)."]},{"cell_type":"markdown","metadata":{"id":"9lv3S_qcUcoI","colab_type":"text"},"source":["### Check your configuration"]},{"cell_type":"code","metadata":{"id":"NBjx82RNUcoK","colab_type":"code","outputId":"76ed9fc5-ead7-4b7e-8165-42f9b61e2cce","executionInfo":{"status":"ok","timestamp":1580293238676,"user_tz":-60,"elapsed":4224,"user":{"displayName":"Miguel Fernández","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_ckDCkb0V8ABako_2n9-az8dxyRyTbDJTpzjTKcg=s64","userId":"00918429620522674110"}},"colab":{"base_uri":"https://localhost:8080/","height":114}},"source":["import tensorflow as tf\n","import keras as krs\n","\n","print(tf.__version__)\n","print(krs.__version__)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["1.15.0\n","2.2.5\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"GU41n0XMUcoR","colab_type":"text"},"source":["## MNIST database\n","\n","\n","The MNIST database contains a training set consisting of 60,000 examples of scans of hand-written numbers from 0 to 9 (classification problem with 10 classes).\n","\n","The test set contains 10,000 examples.\n","\n","Each image has a size of 28x28 pixels. They constitute 28 * 28 = 784 inputs to the network.\n","\n","In machine learning and image recognition community, the MNIST database serves as a kind of `Hello world` problem.\n","\n","\n","Read more about the MNIST database:\n","\n","http://yann.lecun.com/exdb/mnist/\n","\n"]},{"cell_type":"markdown","metadata":{"id":"C4FpHoSLUcoU","colab_type":"text"},"source":["## Getting MNIST\n","\n","The MNIST database can be downloaded in a binary version directly from the website:\n","\n","http://yann.lecun.com/exdb/mnist/\n","\n","\n","In the form of csv files , the MNIST database is available on the website:\n","\n","https://pjreddie.com/projects/mnist-in-csv/\n","\n","\n","The most convenient way, however, is to use the MNIST database import using the Keras library. At the first import, this database will be downloaded automatically (about 12MB). It will be placed in the directory `~ / .keras / datasets / mnist.pkl.gz`.\n","\n","Below is an example code that reads training and test data, and displays several sample images."]},{"cell_type":"code","metadata":{"id":"yrijdOG6UcoW","colab_type":"code","outputId":"46a0c0e5-d705-4e26-a734-2a9a2795869d","executionInfo":{"status":"ok","timestamp":1580293243029,"user_tz":-60,"elapsed":8565,"user":{"displayName":"Miguel Fernández","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_ckDCkb0V8ABako_2n9-az8dxyRyTbDJTpzjTKcg=s64","userId":"00918429620522674110"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["%matplotlib notebook\n","import tensorflow as tf\n","import keras as krs\n","import numpy as np\n","\n","from keras.datasets import mnist\n","import matplotlib.pyplot as plt\n","\n","(xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n","print('xtrain.shape',xtrain.shape)\n","print('ytrain.shape',ytrain.shape)\n","print('xtest.shape',xtest.shape)\n","print('ytest.shape',ytest.shape)\n","\n","#wyswietlenie pierwszego przykladu\n","plt.imshow(xtest[0,:,:], cmap=plt.get_cmap('gray'))\n","\n","#Wyswietlenie kilku pierwszych przykladow\n","rows = 8\n","cols = 10\n","counter = 0\n","\n","images = None\n","\n","for i in range(rows):\n","    current_row = None\n","    for j in range(cols):\n","        im = xtest[counter,:,:]\n","        counter = counter + 1\n","        if current_row is None:\n","            current_row = im\n","        else:\n","            current_row = np.hstack((current_row, im))\n","    if images is None:\n","        images = current_row\n","    else:\n","        images = np.vstack((images, current_row))\n","        \n","plt.figure()\n","plt.imshow(images, cmap=plt.get_cmap('gray'))\n","\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","xtrain.shape (60000, 28, 28)\n","ytrain.shape (60000,)\n","xtest.shape (10000, 28, 28)\n","ytest.shape (10000,)\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/javascript":["/* Put everything inside the global mpl namespace */\n","window.mpl = {};\n","\n","\n","mpl.get_websocket_type = function() {\n","    if (typeof(WebSocket) !== 'undefined') {\n","        return WebSocket;\n","    } else if (typeof(MozWebSocket) !== 'undefined') {\n","        return MozWebSocket;\n","    } else {\n","        alert('Your browser does not have WebSocket support. ' +\n","              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n","              'Firefox 4 and 5 are also supported but you ' +\n","              'have to enable WebSockets in about:config.');\n","    };\n","}\n","\n","mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n","    this.id = figure_id;\n","\n","    this.ws = websocket;\n","\n","    this.supports_binary = (this.ws.binaryType != undefined);\n","\n","    if (!this.supports_binary) {\n","        var warnings = document.getElementById(\"mpl-warnings\");\n","        if (warnings) {\n","            warnings.style.display = 'block';\n","            warnings.textContent = (\n","                \"This browser does not support binary websocket messages. \" +\n","                    \"Performance may be slow.\");\n","        }\n","    }\n","\n","    this.imageObj = new Image();\n","\n","    this.context = undefined;\n","    this.message = undefined;\n","    this.canvas = undefined;\n","    this.rubberband_canvas = undefined;\n","    this.rubberband_context = undefined;\n","    this.format_dropdown = undefined;\n","\n","    this.image_mode = 'full';\n","\n","    this.root = $('<div/>');\n","    this._root_extra_style(this.root)\n","    this.root.attr('style', 'display: inline-block');\n","\n","    $(parent_element).append(this.root);\n","\n","    this._init_header(this);\n","    this._init_canvas(this);\n","    this._init_toolbar(this);\n","\n","    var fig = this;\n","\n","    this.waiting = false;\n","\n","    this.ws.onopen =  function () {\n","            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n","            fig.send_message(\"send_image_mode\", {});\n","            if (mpl.ratio != 1) {\n","                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n","            }\n","            fig.send_message(\"refresh\", {});\n","        }\n","\n","    this.imageObj.onload = function() {\n","            if (fig.image_mode == 'full') {\n","                // Full images could contain transparency (where diff images\n","                // almost always do), so we need to clear the canvas so that\n","                // there is no ghosting.\n","                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n","            }\n","            fig.context.drawImage(fig.imageObj, 0, 0);\n","        };\n","\n","    this.imageObj.onunload = function() {\n","        fig.ws.close();\n","    }\n","\n","    this.ws.onmessage = this._make_on_message_function(this);\n","\n","    this.ondownload = ondownload;\n","}\n","\n","mpl.figure.prototype._init_header = function() {\n","    var titlebar = $(\n","        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n","        'ui-helper-clearfix\"/>');\n","    var titletext = $(\n","        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n","        'text-align: center; padding: 3px;\"/>');\n","    titlebar.append(titletext)\n","    this.root.append(titlebar);\n","    this.header = titletext[0];\n","}\n","\n","\n","\n","mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n","\n","}\n","\n","\n","mpl.figure.prototype._root_extra_style = function(canvas_div) {\n","\n","}\n","\n","mpl.figure.prototype._init_canvas = function() {\n","    var fig = this;\n","\n","    var canvas_div = $('<div/>');\n","\n","    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n","\n","    function canvas_keyboard_event(event) {\n","        return fig.key_event(event, event['data']);\n","    }\n","\n","    canvas_div.keydown('key_press', canvas_keyboard_event);\n","    canvas_div.keyup('key_release', canvas_keyboard_event);\n","    this.canvas_div = canvas_div\n","    this._canvas_extra_style(canvas_div)\n","    this.root.append(canvas_div);\n","\n","    var canvas = $('<canvas/>');\n","    canvas.addClass('mpl-canvas');\n","    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n","\n","    this.canvas = canvas[0];\n","    this.context = canvas[0].getContext(\"2d\");\n","\n","    var backingStore = this.context.backingStorePixelRatio ||\n","\tthis.context.webkitBackingStorePixelRatio ||\n","\tthis.context.mozBackingStorePixelRatio ||\n","\tthis.context.msBackingStorePixelRatio ||\n","\tthis.context.oBackingStorePixelRatio ||\n","\tthis.context.backingStorePixelRatio || 1;\n","\n","    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n","\n","    var rubberband = $('<canvas/>');\n","    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n","\n","    var pass_mouse_events = true;\n","\n","    canvas_div.resizable({\n","        start: function(event, ui) {\n","            pass_mouse_events = false;\n","        },\n","        resize: function(event, ui) {\n","            fig.request_resize(ui.size.width, ui.size.height);\n","        },\n","        stop: function(event, ui) {\n","            pass_mouse_events = true;\n","            fig.request_resize(ui.size.width, ui.size.height);\n","        },\n","    });\n","\n","    function mouse_event_fn(event) {\n","        if (pass_mouse_events)\n","            return fig.mouse_event(event, event['data']);\n","    }\n","\n","    rubberband.mousedown('button_press', mouse_event_fn);\n","    rubberband.mouseup('button_release', mouse_event_fn);\n","    // Throttle sequential mouse events to 1 every 20ms.\n","    rubberband.mousemove('motion_notify', mouse_event_fn);\n","\n","    rubberband.mouseenter('figure_enter', mouse_event_fn);\n","    rubberband.mouseleave('figure_leave', mouse_event_fn);\n","\n","    canvas_div.on(\"wheel\", function (event) {\n","        event = event.originalEvent;\n","        event['data'] = 'scroll'\n","        if (event.deltaY < 0) {\n","            event.step = 1;\n","        } else {\n","            event.step = -1;\n","        }\n","        mouse_event_fn(event);\n","    });\n","\n","    canvas_div.append(canvas);\n","    canvas_div.append(rubberband);\n","\n","    this.rubberband = rubberband;\n","    this.rubberband_canvas = rubberband[0];\n","    this.rubberband_context = rubberband[0].getContext(\"2d\");\n","    this.rubberband_context.strokeStyle = \"#000000\";\n","\n","    this._resize_canvas = function(width, height) {\n","        // Keep the size of the canvas, canvas container, and rubber band\n","        // canvas in synch.\n","        canvas_div.css('width', width)\n","        canvas_div.css('height', height)\n","\n","        canvas.attr('width', width * mpl.ratio);\n","        canvas.attr('height', height * mpl.ratio);\n","        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n","\n","        rubberband.attr('width', width);\n","        rubberband.attr('height', height);\n","    }\n","\n","    // Set the figure to an initial 600x600px, this will subsequently be updated\n","    // upon first draw.\n","    this._resize_canvas(600, 600);\n","\n","    // Disable right mouse context menu.\n","    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n","        return false;\n","    });\n","\n","    function set_focus () {\n","        canvas.focus();\n","        canvas_div.focus();\n","    }\n","\n","    window.setTimeout(set_focus, 100);\n","}\n","\n","mpl.figure.prototype._init_toolbar = function() {\n","    var fig = this;\n","\n","    var nav_element = $('<div/>');\n","    nav_element.attr('style', 'width: 100%');\n","    this.root.append(nav_element);\n","\n","    // Define a callback function for later on.\n","    function toolbar_event(event) {\n","        return fig.toolbar_button_onclick(event['data']);\n","    }\n","    function toolbar_mouse_event(event) {\n","        return fig.toolbar_button_onmouseover(event['data']);\n","    }\n","\n","    for(var toolbar_ind in mpl.toolbar_items) {\n","        var name = mpl.toolbar_items[toolbar_ind][0];\n","        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n","        var image = mpl.toolbar_items[toolbar_ind][2];\n","        var method_name = mpl.toolbar_items[toolbar_ind][3];\n","\n","        if (!name) {\n","            // put a spacer in here.\n","            continue;\n","        }\n","        var button = $('<button/>');\n","        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n","                        'ui-button-icon-only');\n","        button.attr('role', 'button');\n","        button.attr('aria-disabled', 'false');\n","        button.click(method_name, toolbar_event);\n","        button.mouseover(tooltip, toolbar_mouse_event);\n","\n","        var icon_img = $('<span/>');\n","        icon_img.addClass('ui-button-icon-primary ui-icon');\n","        icon_img.addClass(image);\n","        icon_img.addClass('ui-corner-all');\n","\n","        var tooltip_span = $('<span/>');\n","        tooltip_span.addClass('ui-button-text');\n","        tooltip_span.html(tooltip);\n","\n","        button.append(icon_img);\n","        button.append(tooltip_span);\n","\n","        nav_element.append(button);\n","    }\n","\n","    var fmt_picker_span = $('<span/>');\n","\n","    var fmt_picker = $('<select/>');\n","    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n","    fmt_picker_span.append(fmt_picker);\n","    nav_element.append(fmt_picker_span);\n","    this.format_dropdown = fmt_picker[0];\n","\n","    for (var ind in mpl.extensions) {\n","        var fmt = mpl.extensions[ind];\n","        var option = $(\n","            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n","        fmt_picker.append(option);\n","    }\n","\n","    // Add hover states to the ui-buttons\n","    $( \".ui-button\" ).hover(\n","        function() { $(this).addClass(\"ui-state-hover\");},\n","        function() { $(this).removeClass(\"ui-state-hover\");}\n","    );\n","\n","    var status_bar = $('<span class=\"mpl-message\"/>');\n","    nav_element.append(status_bar);\n","    this.message = status_bar[0];\n","}\n","\n","mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n","    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n","    // which will in turn request a refresh of the image.\n","    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n","}\n","\n","mpl.figure.prototype.send_message = function(type, properties) {\n","    properties['type'] = type;\n","    properties['figure_id'] = this.id;\n","    this.ws.send(JSON.stringify(properties));\n","}\n","\n","mpl.figure.prototype.send_draw_message = function() {\n","    if (!this.waiting) {\n","        this.waiting = true;\n","        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n","    }\n","}\n","\n","\n","mpl.figure.prototype.handle_save = function(fig, msg) {\n","    var format_dropdown = fig.format_dropdown;\n","    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n","    fig.ondownload(fig, format);\n","}\n","\n","\n","mpl.figure.prototype.handle_resize = function(fig, msg) {\n","    var size = msg['size'];\n","    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n","        fig._resize_canvas(size[0], size[1]);\n","        fig.send_message(\"refresh\", {});\n","    };\n","}\n","\n","mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n","    var x0 = msg['x0'] / mpl.ratio;\n","    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n","    var x1 = msg['x1'] / mpl.ratio;\n","    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n","    x0 = Math.floor(x0) + 0.5;\n","    y0 = Math.floor(y0) + 0.5;\n","    x1 = Math.floor(x1) + 0.5;\n","    y1 = Math.floor(y1) + 0.5;\n","    var min_x = Math.min(x0, x1);\n","    var min_y = Math.min(y0, y1);\n","    var width = Math.abs(x1 - x0);\n","    var height = Math.abs(y1 - y0);\n","\n","    fig.rubberband_context.clearRect(\n","        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n","\n","    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n","}\n","\n","mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n","    // Updates the figure title.\n","    fig.header.textContent = msg['label'];\n","}\n","\n","mpl.figure.prototype.handle_cursor = function(fig, msg) {\n","    var cursor = msg['cursor'];\n","    switch(cursor)\n","    {\n","    case 0:\n","        cursor = 'pointer';\n","        break;\n","    case 1:\n","        cursor = 'default';\n","        break;\n","    case 2:\n","        cursor = 'crosshair';\n","        break;\n","    case 3:\n","        cursor = 'move';\n","        break;\n","    }\n","    fig.rubberband_canvas.style.cursor = cursor;\n","}\n","\n","mpl.figure.prototype.handle_message = function(fig, msg) {\n","    fig.message.textContent = msg['message'];\n","}\n","\n","mpl.figure.prototype.handle_draw = function(fig, msg) {\n","    // Request the server to send over a new figure.\n","    fig.send_draw_message();\n","}\n","\n","mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n","    fig.image_mode = msg['mode'];\n","}\n","\n","mpl.figure.prototype.updated_canvas_event = function() {\n","    // Called whenever the canvas gets updated.\n","    this.send_message(\"ack\", {});\n","}\n","\n","// A function to construct a web socket function for onmessage handling.\n","// Called in the figure constructor.\n","mpl.figure.prototype._make_on_message_function = function(fig) {\n","    return function socket_on_message(evt) {\n","        if (evt.data instanceof Blob) {\n","            /* FIXME: We get \"Resource interpreted as Image but\n","             * transferred with MIME type text/plain:\" errors on\n","             * Chrome.  But how to set the MIME type?  It doesn't seem\n","             * to be part of the websocket stream */\n","            evt.data.type = \"image/png\";\n","\n","            /* Free the memory for the previous frames */\n","            if (fig.imageObj.src) {\n","                (window.URL || window.webkitURL).revokeObjectURL(\n","                    fig.imageObj.src);\n","            }\n","\n","            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n","                evt.data);\n","            fig.updated_canvas_event();\n","            fig.waiting = false;\n","            return;\n","        }\n","        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n","            fig.imageObj.src = evt.data;\n","            fig.updated_canvas_event();\n","            fig.waiting = false;\n","            return;\n","        }\n","\n","        var msg = JSON.parse(evt.data);\n","        var msg_type = msg['type'];\n","\n","        // Call the  \"handle_{type}\" callback, which takes\n","        // the figure and JSON message as its only arguments.\n","        try {\n","            var callback = fig[\"handle_\" + msg_type];\n","        } catch (e) {\n","            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n","            return;\n","        }\n","\n","        if (callback) {\n","            try {\n","                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n","                callback(fig, msg);\n","            } catch (e) {\n","                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n","            }\n","        }\n","    };\n","}\n","\n","// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n","mpl.findpos = function(e) {\n","    //this section is from http://www.quirksmode.org/js/events_properties.html\n","    var targ;\n","    if (!e)\n","        e = window.event;\n","    if (e.target)\n","        targ = e.target;\n","    else if (e.srcElement)\n","        targ = e.srcElement;\n","    if (targ.nodeType == 3) // defeat Safari bug\n","        targ = targ.parentNode;\n","\n","    // jQuery normalizes the pageX and pageY\n","    // pageX,Y are the mouse positions relative to the document\n","    // offset() returns the position of the element relative to the document\n","    var x = e.pageX - $(targ).offset().left;\n","    var y = e.pageY - $(targ).offset().top;\n","\n","    return {\"x\": x, \"y\": y};\n","};\n","\n","/*\n"," * return a copy of an object with only non-object keys\n"," * we need this to avoid circular references\n"," * http://stackoverflow.com/a/24161582/3208463\n"," */\n","function simpleKeys (original) {\n","  return Object.keys(original).reduce(function (obj, key) {\n","    if (typeof original[key] !== 'object')\n","        obj[key] = original[key]\n","    return obj;\n","  }, {});\n","}\n","\n","mpl.figure.prototype.mouse_event = function(event, name) {\n","    var canvas_pos = mpl.findpos(event)\n","\n","    if (name === 'button_press')\n","    {\n","        this.canvas.focus();\n","        this.canvas_div.focus();\n","    }\n","\n","    var x = canvas_pos.x * mpl.ratio;\n","    var y = canvas_pos.y * mpl.ratio;\n","\n","    this.send_message(name, {x: x, y: y, button: event.button,\n","                             step: event.step,\n","                             guiEvent: simpleKeys(event)});\n","\n","    /* This prevents the web browser from automatically changing to\n","     * the text insertion cursor when the button is pressed.  We want\n","     * to control all of the cursor setting manually through the\n","     * 'cursor' event from matplotlib */\n","    event.preventDefault();\n","    return false;\n","}\n","\n","mpl.figure.prototype._key_event_extra = function(event, name) {\n","    // Handle any extra behaviour associated with a key event\n","}\n","\n","mpl.figure.prototype.key_event = function(event, name) {\n","\n","    // Prevent repeat events\n","    if (name == 'key_press')\n","    {\n","        if (event.which === this._key)\n","            return;\n","        else\n","            this._key = event.which;\n","    }\n","    if (name == 'key_release')\n","        this._key = null;\n","\n","    var value = '';\n","    if (event.ctrlKey && event.which != 17)\n","        value += \"ctrl+\";\n","    if (event.altKey && event.which != 18)\n","        value += \"alt+\";\n","    if (event.shiftKey && event.which != 16)\n","        value += \"shift+\";\n","\n","    value += 'k';\n","    value += event.which.toString();\n","\n","    this._key_event_extra(event, name);\n","\n","    this.send_message(name, {key: value,\n","                             guiEvent: simpleKeys(event)});\n","    return false;\n","}\n","\n","mpl.figure.prototype.toolbar_button_onclick = function(name) {\n","    if (name == 'download') {\n","        this.handle_save(this, null);\n","    } else {\n","        this.send_message(\"toolbar_button\", {name: name});\n","    }\n","};\n","\n","mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n","    this.message.textContent = tooltip;\n","};\n","mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n","\n","mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n","\n","mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n","    // Create a \"websocket\"-like object which calls the given IPython comm\n","    // object with the appropriate methods. Currently this is a non binary\n","    // socket, so there is still some room for performance tuning.\n","    var ws = {};\n","\n","    ws.close = function() {\n","        comm.close()\n","    };\n","    ws.send = function(m) {\n","        //console.log('sending', m);\n","        comm.send(m);\n","    };\n","    // Register the callback with on_msg.\n","    comm.on_msg(function(msg) {\n","        //console.log('receiving', msg['content']['data'], msg);\n","        // Pass the mpl event to the overridden (by mpl) onmessage function.\n","        ws.onmessage(msg['content']['data'])\n","    });\n","    return ws;\n","}\n","\n","mpl.mpl_figure_comm = function(comm, msg) {\n","    // This is the function which gets called when the mpl process\n","    // starts-up an IPython Comm through the \"matplotlib\" channel.\n","\n","    var id = msg.content.data.id;\n","    // Get hold of the div created by the display call when the Comm\n","    // socket was opened in Python.\n","    var element = $(\"#\" + id);\n","    var ws_proxy = comm_websocket_adapter(comm)\n","\n","    function ondownload(figure, format) {\n","        window.open(figure.imageObj.src);\n","    }\n","\n","    var fig = new mpl.figure(id, ws_proxy,\n","                           ondownload,\n","                           element.get(0));\n","\n","    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n","    // web socket which is closed, not our websocket->open comm proxy.\n","    ws_proxy.onopen();\n","\n","    fig.parent_element = element.get(0);\n","    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n","    if (!fig.cell_info) {\n","        console.error(\"Failed to find cell for figure\", id, fig);\n","        return;\n","    }\n","\n","    var output_index = fig.cell_info[2]\n","    var cell = fig.cell_info[0];\n","\n","};\n","\n","mpl.figure.prototype.handle_close = function(fig, msg) {\n","    var width = fig.canvas.width/mpl.ratio\n","    fig.root.unbind('remove')\n","\n","    // Update the output cell to use the data from the current canvas.\n","    fig.push_to_output();\n","    var dataURL = fig.canvas.toDataURL();\n","    // Re-enable the keyboard manager in IPython - without this line, in FF,\n","    // the notebook keyboard shortcuts fail.\n","    IPython.keyboard_manager.enable()\n","    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n","    fig.close_ws(fig, msg);\n","}\n","\n","mpl.figure.prototype.close_ws = function(fig, msg){\n","    fig.send_message('closing', msg);\n","    // fig.ws.close()\n","}\n","\n","mpl.figure.prototype.push_to_output = function(remove_interactive) {\n","    // Turn the data on the canvas into data in the output cell.\n","    var width = this.canvas.width/mpl.ratio\n","    var dataURL = this.canvas.toDataURL();\n","    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n","}\n","\n","mpl.figure.prototype.updated_canvas_event = function() {\n","    // Tell IPython that the notebook contents must change.\n","    IPython.notebook.set_dirty(true);\n","    this.send_message(\"ack\", {});\n","    var fig = this;\n","    // Wait a second, then push the new image to the DOM so\n","    // that it is saved nicely (might be nice to debounce this).\n","    setTimeout(function () { fig.push_to_output() }, 1000);\n","}\n","\n","mpl.figure.prototype._init_toolbar = function() {\n","    var fig = this;\n","\n","    var nav_element = $('<div/>');\n","    nav_element.attr('style', 'width: 100%');\n","    this.root.append(nav_element);\n","\n","    // Define a callback function for later on.\n","    function toolbar_event(event) {\n","        return fig.toolbar_button_onclick(event['data']);\n","    }\n","    function toolbar_mouse_event(event) {\n","        return fig.toolbar_button_onmouseover(event['data']);\n","    }\n","\n","    for(var toolbar_ind in mpl.toolbar_items){\n","        var name = mpl.toolbar_items[toolbar_ind][0];\n","        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n","        var image = mpl.toolbar_items[toolbar_ind][2];\n","        var method_name = mpl.toolbar_items[toolbar_ind][3];\n","\n","        if (!name) { continue; };\n","\n","        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n","        button.click(method_name, toolbar_event);\n","        button.mouseover(tooltip, toolbar_mouse_event);\n","        nav_element.append(button);\n","    }\n","\n","    // Add the status bar.\n","    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n","    nav_element.append(status_bar);\n","    this.message = status_bar[0];\n","\n","    // Add the close button to the window.\n","    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n","    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n","    button.click(function (evt) { fig.handle_close(fig, {}); } );\n","    button.mouseover('Stop Interaction', toolbar_mouse_event);\n","    buttongrp.append(button);\n","    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n","    titlebar.prepend(buttongrp);\n","}\n","\n","mpl.figure.prototype._root_extra_style = function(el){\n","    var fig = this\n","    el.on(\"remove\", function(){\n","\tfig.close_ws(fig, {});\n","    });\n","}\n","\n","mpl.figure.prototype._canvas_extra_style = function(el){\n","    // this is important to make the div 'focusable\n","    el.attr('tabindex', 0)\n","    // reach out to IPython and tell the keyboard manager to turn it's self\n","    // off when our div gets focus\n","\n","    // location in version 3\n","    if (IPython.notebook.keyboard_manager) {\n","        IPython.notebook.keyboard_manager.register_events(el);\n","    }\n","    else {\n","        // location in version 2\n","        IPython.keyboard_manager.register_events(el);\n","    }\n","\n","}\n","\n","mpl.figure.prototype._key_event_extra = function(event, name) {\n","    var manager = IPython.notebook.keyboard_manager;\n","    if (!manager)\n","        manager = IPython.keyboard_manager;\n","\n","    // Check for shift+enter\n","    if (event.shiftKey && event.which == 13) {\n","        this.canvas_div.blur();\n","        // select the cell after this one\n","        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n","        IPython.notebook.select(index + 1);\n","    }\n","}\n","\n","mpl.figure.prototype.handle_save = function(fig, msg) {\n","    fig.ondownload(fig, null);\n","}\n","\n","\n","mpl.find_output_cell = function(html_output) {\n","    // Return the cell and output element which can be found *uniquely* in the notebook.\n","    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n","    // IPython event is triggered only after the cells have been serialised, which for\n","    // our purposes (turning an active figure into a static one), is too late.\n","    var cells = IPython.notebook.get_cells();\n","    var ncells = cells.length;\n","    for (var i=0; i<ncells; i++) {\n","        var cell = cells[i];\n","        if (cell.cell_type === 'code'){\n","            for (var j=0; j<cell.output_area.outputs.length; j++) {\n","                var data = cell.output_area.outputs[j];\n","                if (data.data) {\n","                    // IPython >= 3 moved mimebundle to data attribute of output\n","                    data = data.data;\n","                }\n","                if (data['text/html'] == html_output) {\n","                    return [cell, data, j];\n","                }\n","            }\n","        }\n","    }\n","}\n","\n","// Register the function which deals with the matplotlib target/channel.\n","// The kernel may be null if the page has been refreshed.\n","if (IPython.notebook.kernel != null) {\n","    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n","}\n"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<div id='8b45aafc-8c68-4011-be4c-bb79650230d7'></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["/* Put everything inside the global mpl namespace */\n","window.mpl = {};\n","\n","\n","mpl.get_websocket_type = function() {\n","    if (typeof(WebSocket) !== 'undefined') {\n","        return WebSocket;\n","    } else if (typeof(MozWebSocket) !== 'undefined') {\n","        return MozWebSocket;\n","    } else {\n","        alert('Your browser does not have WebSocket support. ' +\n","              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n","              'Firefox 4 and 5 are also supported but you ' +\n","              'have to enable WebSockets in about:config.');\n","    };\n","}\n","\n","mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n","    this.id = figure_id;\n","\n","    this.ws = websocket;\n","\n","    this.supports_binary = (this.ws.binaryType != undefined);\n","\n","    if (!this.supports_binary) {\n","        var warnings = document.getElementById(\"mpl-warnings\");\n","        if (warnings) {\n","            warnings.style.display = 'block';\n","            warnings.textContent = (\n","                \"This browser does not support binary websocket messages. \" +\n","                    \"Performance may be slow.\");\n","        }\n","    }\n","\n","    this.imageObj = new Image();\n","\n","    this.context = undefined;\n","    this.message = undefined;\n","    this.canvas = undefined;\n","    this.rubberband_canvas = undefined;\n","    this.rubberband_context = undefined;\n","    this.format_dropdown = undefined;\n","\n","    this.image_mode = 'full';\n","\n","    this.root = $('<div/>');\n","    this._root_extra_style(this.root)\n","    this.root.attr('style', 'display: inline-block');\n","\n","    $(parent_element).append(this.root);\n","\n","    this._init_header(this);\n","    this._init_canvas(this);\n","    this._init_toolbar(this);\n","\n","    var fig = this;\n","\n","    this.waiting = false;\n","\n","    this.ws.onopen =  function () {\n","            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n","            fig.send_message(\"send_image_mode\", {});\n","            if (mpl.ratio != 1) {\n","                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n","            }\n","            fig.send_message(\"refresh\", {});\n","        }\n","\n","    this.imageObj.onload = function() {\n","            if (fig.image_mode == 'full') {\n","                // Full images could contain transparency (where diff images\n","                // almost always do), so we need to clear the canvas so that\n","                // there is no ghosting.\n","                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n","            }\n","            fig.context.drawImage(fig.imageObj, 0, 0);\n","        };\n","\n","    this.imageObj.onunload = function() {\n","        fig.ws.close();\n","    }\n","\n","    this.ws.onmessage = this._make_on_message_function(this);\n","\n","    this.ondownload = ondownload;\n","}\n","\n","mpl.figure.prototype._init_header = function() {\n","    var titlebar = $(\n","        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n","        'ui-helper-clearfix\"/>');\n","    var titletext = $(\n","        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n","        'text-align: center; padding: 3px;\"/>');\n","    titlebar.append(titletext)\n","    this.root.append(titlebar);\n","    this.header = titletext[0];\n","}\n","\n","\n","\n","mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n","\n","}\n","\n","\n","mpl.figure.prototype._root_extra_style = function(canvas_div) {\n","\n","}\n","\n","mpl.figure.prototype._init_canvas = function() {\n","    var fig = this;\n","\n","    var canvas_div = $('<div/>');\n","\n","    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n","\n","    function canvas_keyboard_event(event) {\n","        return fig.key_event(event, event['data']);\n","    }\n","\n","    canvas_div.keydown('key_press', canvas_keyboard_event);\n","    canvas_div.keyup('key_release', canvas_keyboard_event);\n","    this.canvas_div = canvas_div\n","    this._canvas_extra_style(canvas_div)\n","    this.root.append(canvas_div);\n","\n","    var canvas = $('<canvas/>');\n","    canvas.addClass('mpl-canvas');\n","    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n","\n","    this.canvas = canvas[0];\n","    this.context = canvas[0].getContext(\"2d\");\n","\n","    var backingStore = this.context.backingStorePixelRatio ||\n","\tthis.context.webkitBackingStorePixelRatio ||\n","\tthis.context.mozBackingStorePixelRatio ||\n","\tthis.context.msBackingStorePixelRatio ||\n","\tthis.context.oBackingStorePixelRatio ||\n","\tthis.context.backingStorePixelRatio || 1;\n","\n","    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n","\n","    var rubberband = $('<canvas/>');\n","    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n","\n","    var pass_mouse_events = true;\n","\n","    canvas_div.resizable({\n","        start: function(event, ui) {\n","            pass_mouse_events = false;\n","        },\n","        resize: function(event, ui) {\n","            fig.request_resize(ui.size.width, ui.size.height);\n","        },\n","        stop: function(event, ui) {\n","            pass_mouse_events = true;\n","            fig.request_resize(ui.size.width, ui.size.height);\n","        },\n","    });\n","\n","    function mouse_event_fn(event) {\n","        if (pass_mouse_events)\n","            return fig.mouse_event(event, event['data']);\n","    }\n","\n","    rubberband.mousedown('button_press', mouse_event_fn);\n","    rubberband.mouseup('button_release', mouse_event_fn);\n","    // Throttle sequential mouse events to 1 every 20ms.\n","    rubberband.mousemove('motion_notify', mouse_event_fn);\n","\n","    rubberband.mouseenter('figure_enter', mouse_event_fn);\n","    rubberband.mouseleave('figure_leave', mouse_event_fn);\n","\n","    canvas_div.on(\"wheel\", function (event) {\n","        event = event.originalEvent;\n","        event['data'] = 'scroll'\n","        if (event.deltaY < 0) {\n","            event.step = 1;\n","        } else {\n","            event.step = -1;\n","        }\n","        mouse_event_fn(event);\n","    });\n","\n","    canvas_div.append(canvas);\n","    canvas_div.append(rubberband);\n","\n","    this.rubberband = rubberband;\n","    this.rubberband_canvas = rubberband[0];\n","    this.rubberband_context = rubberband[0].getContext(\"2d\");\n","    this.rubberband_context.strokeStyle = \"#000000\";\n","\n","    this._resize_canvas = function(width, height) {\n","        // Keep the size of the canvas, canvas container, and rubber band\n","        // canvas in synch.\n","        canvas_div.css('width', width)\n","        canvas_div.css('height', height)\n","\n","        canvas.attr('width', width * mpl.ratio);\n","        canvas.attr('height', height * mpl.ratio);\n","        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n","\n","        rubberband.attr('width', width);\n","        rubberband.attr('height', height);\n","    }\n","\n","    // Set the figure to an initial 600x600px, this will subsequently be updated\n","    // upon first draw.\n","    this._resize_canvas(600, 600);\n","\n","    // Disable right mouse context menu.\n","    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n","        return false;\n","    });\n","\n","    function set_focus () {\n","        canvas.focus();\n","        canvas_div.focus();\n","    }\n","\n","    window.setTimeout(set_focus, 100);\n","}\n","\n","mpl.figure.prototype._init_toolbar = function() {\n","    var fig = this;\n","\n","    var nav_element = $('<div/>');\n","    nav_element.attr('style', 'width: 100%');\n","    this.root.append(nav_element);\n","\n","    // Define a callback function for later on.\n","    function toolbar_event(event) {\n","        return fig.toolbar_button_onclick(event['data']);\n","    }\n","    function toolbar_mouse_event(event) {\n","        return fig.toolbar_button_onmouseover(event['data']);\n","    }\n","\n","    for(var toolbar_ind in mpl.toolbar_items) {\n","        var name = mpl.toolbar_items[toolbar_ind][0];\n","        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n","        var image = mpl.toolbar_items[toolbar_ind][2];\n","        var method_name = mpl.toolbar_items[toolbar_ind][3];\n","\n","        if (!name) {\n","            // put a spacer in here.\n","            continue;\n","        }\n","        var button = $('<button/>');\n","        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n","                        'ui-button-icon-only');\n","        button.attr('role', 'button');\n","        button.attr('aria-disabled', 'false');\n","        button.click(method_name, toolbar_event);\n","        button.mouseover(tooltip, toolbar_mouse_event);\n","\n","        var icon_img = $('<span/>');\n","        icon_img.addClass('ui-button-icon-primary ui-icon');\n","        icon_img.addClass(image);\n","        icon_img.addClass('ui-corner-all');\n","\n","        var tooltip_span = $('<span/>');\n","        tooltip_span.addClass('ui-button-text');\n","        tooltip_span.html(tooltip);\n","\n","        button.append(icon_img);\n","        button.append(tooltip_span);\n","\n","        nav_element.append(button);\n","    }\n","\n","    var fmt_picker_span = $('<span/>');\n","\n","    var fmt_picker = $('<select/>');\n","    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n","    fmt_picker_span.append(fmt_picker);\n","    nav_element.append(fmt_picker_span);\n","    this.format_dropdown = fmt_picker[0];\n","\n","    for (var ind in mpl.extensions) {\n","        var fmt = mpl.extensions[ind];\n","        var option = $(\n","            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n","        fmt_picker.append(option);\n","    }\n","\n","    // Add hover states to the ui-buttons\n","    $( \".ui-button\" ).hover(\n","        function() { $(this).addClass(\"ui-state-hover\");},\n","        function() { $(this).removeClass(\"ui-state-hover\");}\n","    );\n","\n","    var status_bar = $('<span class=\"mpl-message\"/>');\n","    nav_element.append(status_bar);\n","    this.message = status_bar[0];\n","}\n","\n","mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n","    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n","    // which will in turn request a refresh of the image.\n","    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n","}\n","\n","mpl.figure.prototype.send_message = function(type, properties) {\n","    properties['type'] = type;\n","    properties['figure_id'] = this.id;\n","    this.ws.send(JSON.stringify(properties));\n","}\n","\n","mpl.figure.prototype.send_draw_message = function() {\n","    if (!this.waiting) {\n","        this.waiting = true;\n","        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n","    }\n","}\n","\n","\n","mpl.figure.prototype.handle_save = function(fig, msg) {\n","    var format_dropdown = fig.format_dropdown;\n","    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n","    fig.ondownload(fig, format);\n","}\n","\n","\n","mpl.figure.prototype.handle_resize = function(fig, msg) {\n","    var size = msg['size'];\n","    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n","        fig._resize_canvas(size[0], size[1]);\n","        fig.send_message(\"refresh\", {});\n","    };\n","}\n","\n","mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n","    var x0 = msg['x0'] / mpl.ratio;\n","    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n","    var x1 = msg['x1'] / mpl.ratio;\n","    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n","    x0 = Math.floor(x0) + 0.5;\n","    y0 = Math.floor(y0) + 0.5;\n","    x1 = Math.floor(x1) + 0.5;\n","    y1 = Math.floor(y1) + 0.5;\n","    var min_x = Math.min(x0, x1);\n","    var min_y = Math.min(y0, y1);\n","    var width = Math.abs(x1 - x0);\n","    var height = Math.abs(y1 - y0);\n","\n","    fig.rubberband_context.clearRect(\n","        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n","\n","    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n","}\n","\n","mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n","    // Updates the figure title.\n","    fig.header.textContent = msg['label'];\n","}\n","\n","mpl.figure.prototype.handle_cursor = function(fig, msg) {\n","    var cursor = msg['cursor'];\n","    switch(cursor)\n","    {\n","    case 0:\n","        cursor = 'pointer';\n","        break;\n","    case 1:\n","        cursor = 'default';\n","        break;\n","    case 2:\n","        cursor = 'crosshair';\n","        break;\n","    case 3:\n","        cursor = 'move';\n","        break;\n","    }\n","    fig.rubberband_canvas.style.cursor = cursor;\n","}\n","\n","mpl.figure.prototype.handle_message = function(fig, msg) {\n","    fig.message.textContent = msg['message'];\n","}\n","\n","mpl.figure.prototype.handle_draw = function(fig, msg) {\n","    // Request the server to send over a new figure.\n","    fig.send_draw_message();\n","}\n","\n","mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n","    fig.image_mode = msg['mode'];\n","}\n","\n","mpl.figure.prototype.updated_canvas_event = function() {\n","    // Called whenever the canvas gets updated.\n","    this.send_message(\"ack\", {});\n","}\n","\n","// A function to construct a web socket function for onmessage handling.\n","// Called in the figure constructor.\n","mpl.figure.prototype._make_on_message_function = function(fig) {\n","    return function socket_on_message(evt) {\n","        if (evt.data instanceof Blob) {\n","            /* FIXME: We get \"Resource interpreted as Image but\n","             * transferred with MIME type text/plain:\" errors on\n","             * Chrome.  But how to set the MIME type?  It doesn't seem\n","             * to be part of the websocket stream */\n","            evt.data.type = \"image/png\";\n","\n","            /* Free the memory for the previous frames */\n","            if (fig.imageObj.src) {\n","                (window.URL || window.webkitURL).revokeObjectURL(\n","                    fig.imageObj.src);\n","            }\n","\n","            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n","                evt.data);\n","            fig.updated_canvas_event();\n","            fig.waiting = false;\n","            return;\n","        }\n","        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n","            fig.imageObj.src = evt.data;\n","            fig.updated_canvas_event();\n","            fig.waiting = false;\n","            return;\n","        }\n","\n","        var msg = JSON.parse(evt.data);\n","        var msg_type = msg['type'];\n","\n","        // Call the  \"handle_{type}\" callback, which takes\n","        // the figure and JSON message as its only arguments.\n","        try {\n","            var callback = fig[\"handle_\" + msg_type];\n","        } catch (e) {\n","            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n","            return;\n","        }\n","\n","        if (callback) {\n","            try {\n","                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n","                callback(fig, msg);\n","            } catch (e) {\n","                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n","            }\n","        }\n","    };\n","}\n","\n","// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n","mpl.findpos = function(e) {\n","    //this section is from http://www.quirksmode.org/js/events_properties.html\n","    var targ;\n","    if (!e)\n","        e = window.event;\n","    if (e.target)\n","        targ = e.target;\n","    else if (e.srcElement)\n","        targ = e.srcElement;\n","    if (targ.nodeType == 3) // defeat Safari bug\n","        targ = targ.parentNode;\n","\n","    // jQuery normalizes the pageX and pageY\n","    // pageX,Y are the mouse positions relative to the document\n","    // offset() returns the position of the element relative to the document\n","    var x = e.pageX - $(targ).offset().left;\n","    var y = e.pageY - $(targ).offset().top;\n","\n","    return {\"x\": x, \"y\": y};\n","};\n","\n","/*\n"," * return a copy of an object with only non-object keys\n"," * we need this to avoid circular references\n"," * http://stackoverflow.com/a/24161582/3208463\n"," */\n","function simpleKeys (original) {\n","  return Object.keys(original).reduce(function (obj, key) {\n","    if (typeof original[key] !== 'object')\n","        obj[key] = original[key]\n","    return obj;\n","  }, {});\n","}\n","\n","mpl.figure.prototype.mouse_event = function(event, name) {\n","    var canvas_pos = mpl.findpos(event)\n","\n","    if (name === 'button_press')\n","    {\n","        this.canvas.focus();\n","        this.canvas_div.focus();\n","    }\n","\n","    var x = canvas_pos.x * mpl.ratio;\n","    var y = canvas_pos.y * mpl.ratio;\n","\n","    this.send_message(name, {x: x, y: y, button: event.button,\n","                             step: event.step,\n","                             guiEvent: simpleKeys(event)});\n","\n","    /* This prevents the web browser from automatically changing to\n","     * the text insertion cursor when the button is pressed.  We want\n","     * to control all of the cursor setting manually through the\n","     * 'cursor' event from matplotlib */\n","    event.preventDefault();\n","    return false;\n","}\n","\n","mpl.figure.prototype._key_event_extra = function(event, name) {\n","    // Handle any extra behaviour associated with a key event\n","}\n","\n","mpl.figure.prototype.key_event = function(event, name) {\n","\n","    // Prevent repeat events\n","    if (name == 'key_press')\n","    {\n","        if (event.which === this._key)\n","            return;\n","        else\n","            this._key = event.which;\n","    }\n","    if (name == 'key_release')\n","        this._key = null;\n","\n","    var value = '';\n","    if (event.ctrlKey && event.which != 17)\n","        value += \"ctrl+\";\n","    if (event.altKey && event.which != 18)\n","        value += \"alt+\";\n","    if (event.shiftKey && event.which != 16)\n","        value += \"shift+\";\n","\n","    value += 'k';\n","    value += event.which.toString();\n","\n","    this._key_event_extra(event, name);\n","\n","    this.send_message(name, {key: value,\n","                             guiEvent: simpleKeys(event)});\n","    return false;\n","}\n","\n","mpl.figure.prototype.toolbar_button_onclick = function(name) {\n","    if (name == 'download') {\n","        this.handle_save(this, null);\n","    } else {\n","        this.send_message(\"toolbar_button\", {name: name});\n","    }\n","};\n","\n","mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n","    this.message.textContent = tooltip;\n","};\n","mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n","\n","mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n","\n","mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n","    // Create a \"websocket\"-like object which calls the given IPython comm\n","    // object with the appropriate methods. Currently this is a non binary\n","    // socket, so there is still some room for performance tuning.\n","    var ws = {};\n","\n","    ws.close = function() {\n","        comm.close()\n","    };\n","    ws.send = function(m) {\n","        //console.log('sending', m);\n","        comm.send(m);\n","    };\n","    // Register the callback with on_msg.\n","    comm.on_msg(function(msg) {\n","        //console.log('receiving', msg['content']['data'], msg);\n","        // Pass the mpl event to the overridden (by mpl) onmessage function.\n","        ws.onmessage(msg['content']['data'])\n","    });\n","    return ws;\n","}\n","\n","mpl.mpl_figure_comm = function(comm, msg) {\n","    // This is the function which gets called when the mpl process\n","    // starts-up an IPython Comm through the \"matplotlib\" channel.\n","\n","    var id = msg.content.data.id;\n","    // Get hold of the div created by the display call when the Comm\n","    // socket was opened in Python.\n","    var element = $(\"#\" + id);\n","    var ws_proxy = comm_websocket_adapter(comm)\n","\n","    function ondownload(figure, format) {\n","        window.open(figure.imageObj.src);\n","    }\n","\n","    var fig = new mpl.figure(id, ws_proxy,\n","                           ondownload,\n","                           element.get(0));\n","\n","    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n","    // web socket which is closed, not our websocket->open comm proxy.\n","    ws_proxy.onopen();\n","\n","    fig.parent_element = element.get(0);\n","    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n","    if (!fig.cell_info) {\n","        console.error(\"Failed to find cell for figure\", id, fig);\n","        return;\n","    }\n","\n","    var output_index = fig.cell_info[2]\n","    var cell = fig.cell_info[0];\n","\n","};\n","\n","mpl.figure.prototype.handle_close = function(fig, msg) {\n","    var width = fig.canvas.width/mpl.ratio\n","    fig.root.unbind('remove')\n","\n","    // Update the output cell to use the data from the current canvas.\n","    fig.push_to_output();\n","    var dataURL = fig.canvas.toDataURL();\n","    // Re-enable the keyboard manager in IPython - without this line, in FF,\n","    // the notebook keyboard shortcuts fail.\n","    IPython.keyboard_manager.enable()\n","    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n","    fig.close_ws(fig, msg);\n","}\n","\n","mpl.figure.prototype.close_ws = function(fig, msg){\n","    fig.send_message('closing', msg);\n","    // fig.ws.close()\n","}\n","\n","mpl.figure.prototype.push_to_output = function(remove_interactive) {\n","    // Turn the data on the canvas into data in the output cell.\n","    var width = this.canvas.width/mpl.ratio\n","    var dataURL = this.canvas.toDataURL();\n","    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n","}\n","\n","mpl.figure.prototype.updated_canvas_event = function() {\n","    // Tell IPython that the notebook contents must change.\n","    IPython.notebook.set_dirty(true);\n","    this.send_message(\"ack\", {});\n","    var fig = this;\n","    // Wait a second, then push the new image to the DOM so\n","    // that it is saved nicely (might be nice to debounce this).\n","    setTimeout(function () { fig.push_to_output() }, 1000);\n","}\n","\n","mpl.figure.prototype._init_toolbar = function() {\n","    var fig = this;\n","\n","    var nav_element = $('<div/>');\n","    nav_element.attr('style', 'width: 100%');\n","    this.root.append(nav_element);\n","\n","    // Define a callback function for later on.\n","    function toolbar_event(event) {\n","        return fig.toolbar_button_onclick(event['data']);\n","    }\n","    function toolbar_mouse_event(event) {\n","        return fig.toolbar_button_onmouseover(event['data']);\n","    }\n","\n","    for(var toolbar_ind in mpl.toolbar_items){\n","        var name = mpl.toolbar_items[toolbar_ind][0];\n","        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n","        var image = mpl.toolbar_items[toolbar_ind][2];\n","        var method_name = mpl.toolbar_items[toolbar_ind][3];\n","\n","        if (!name) { continue; };\n","\n","        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n","        button.click(method_name, toolbar_event);\n","        button.mouseover(tooltip, toolbar_mouse_event);\n","        nav_element.append(button);\n","    }\n","\n","    // Add the status bar.\n","    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n","    nav_element.append(status_bar);\n","    this.message = status_bar[0];\n","\n","    // Add the close button to the window.\n","    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n","    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n","    button.click(function (evt) { fig.handle_close(fig, {}); } );\n","    button.mouseover('Stop Interaction', toolbar_mouse_event);\n","    buttongrp.append(button);\n","    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n","    titlebar.prepend(buttongrp);\n","}\n","\n","mpl.figure.prototype._root_extra_style = function(el){\n","    var fig = this\n","    el.on(\"remove\", function(){\n","\tfig.close_ws(fig, {});\n","    });\n","}\n","\n","mpl.figure.prototype._canvas_extra_style = function(el){\n","    // this is important to make the div 'focusable\n","    el.attr('tabindex', 0)\n","    // reach out to IPython and tell the keyboard manager to turn it's self\n","    // off when our div gets focus\n","\n","    // location in version 3\n","    if (IPython.notebook.keyboard_manager) {\n","        IPython.notebook.keyboard_manager.register_events(el);\n","    }\n","    else {\n","        // location in version 2\n","        IPython.keyboard_manager.register_events(el);\n","    }\n","\n","}\n","\n","mpl.figure.prototype._key_event_extra = function(event, name) {\n","    var manager = IPython.notebook.keyboard_manager;\n","    if (!manager)\n","        manager = IPython.keyboard_manager;\n","\n","    // Check for shift+enter\n","    if (event.shiftKey && event.which == 13) {\n","        this.canvas_div.blur();\n","        // select the cell after this one\n","        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n","        IPython.notebook.select(index + 1);\n","    }\n","}\n","\n","mpl.figure.prototype.handle_save = function(fig, msg) {\n","    fig.ondownload(fig, null);\n","}\n","\n","\n","mpl.find_output_cell = function(html_output) {\n","    // Return the cell and output element which can be found *uniquely* in the notebook.\n","    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n","    // IPython event is triggered only after the cells have been serialised, which for\n","    // our purposes (turning an active figure into a static one), is too late.\n","    var cells = IPython.notebook.get_cells();\n","    var ncells = cells.length;\n","    for (var i=0; i<ncells; i++) {\n","        var cell = cells[i];\n","        if (cell.cell_type === 'code'){\n","            for (var j=0; j<cell.output_area.outputs.length; j++) {\n","                var data = cell.output_area.outputs[j];\n","                if (data.data) {\n","                    // IPython >= 3 moved mimebundle to data attribute of output\n","                    data = data.data;\n","                }\n","                if (data['text/html'] == html_output) {\n","                    return [cell, data, j];\n","                }\n","            }\n","        }\n","    }\n","}\n","\n","// Register the function which deals with the matplotlib target/channel.\n","// The kernel may be null if the page has been refreshed.\n","if (IPython.notebook.kernel != null) {\n","    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n","}\n"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<div id='82c68d94-0230-484a-91b5-b2e71d16ecd2'></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"2OoVzKhzUcob","colab_type":"text"},"source":["## MLP network with one layer hidden in the MNIST problem\n","\n","We will check how the MNIST problem will be dealt with by the MLP neural network with one hidden layer."]},{"cell_type":"markdown","metadata":{"id":"Bslb7MaUUcod","colab_type":"text"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"KC1DtpyVUcoj","colab_type":"code","outputId":"f7c04c35-8385-4712-c747-887ad892da31","executionInfo":{"status":"ok","timestamp":1580293243032,"user_tz":-60,"elapsed":8547,"user":{"displayName":"Miguel Fernández","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_ckDCkb0V8ABako_2n9-az8dxyRyTbDJTpzjTKcg=s64","userId":"00918429620522674110"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import tensorflow as tf\n","import numpy\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.models import load_model\n","from keras.utils import np_utils\n","\n","#If necessary, change the current catalog\n","#import os\n","#path = '.'\n","#os.chdir(path)\n","\n","print(tf.__version__)\n","print(keras.__version__)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.15.0\n","2.2.5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"c6NYfRV9Ucoo","colab_type":"text"},"source":["### Loading data\n","\n","Please note that the data is stored as a 3-dimensional tensor."]},{"cell_type":"code","metadata":{"id":"lrPrC9OMUcop","colab_type":"code","outputId":"50fab6de-0e4c-48cb-a70f-7f6a08ec8883","executionInfo":{"status":"ok","timestamp":1580293243036,"user_tz":-60,"elapsed":8528,"user":{"displayName":"Miguel Fernández","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_ckDCkb0V8ABako_2n9-az8dxyRyTbDJTpzjTKcg=s64","userId":"00918429620522674110"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["(xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n","print('xtrain.shape',xtrain.shape)\n","print('ytrain.shape',ytrain.shape)\n","print('xtest.shape',xtest.shape)\n","print('ytest.shape',ytest.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["xtrain.shape (60000, 28, 28)\n","ytrain.shape (60000,)\n","xtest.shape (10000, 28, 28)\n","ytest.shape (10000,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tSWgrEMyUcoy","colab_type":"text"},"source":["### Seed initialization (to allow for repeatability of calculations)"]},{"cell_type":"code","metadata":{"id":"Mtv2DMrtUco1","colab_type":"code","colab":{}},"source":["seed = 12345\n","numpy.random.seed(seed)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TiSmfcIlUco5","colab_type":"text"},"source":["### Preparation of input data\n","\n","The original 28x28 pixel images will be fed into the network input layer as vectors with a length of 784.\n","\n","In addition, the normalization of pixel values from the interval [0.255] into interval [0,1] will have a positive impact on the network learning process.\n"]},{"cell_type":"code","metadata":{"id":"5HMgrECZUco6","colab_type":"code","outputId":"b41bed8a-edd8-4a5f-e5c1-e7d970d10819","executionInfo":{"status":"ok","timestamp":1580293243044,"user_tz":-60,"elapsed":8498,"user":{"displayName":"Miguel Fernández","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_ckDCkb0V8ABako_2n9-az8dxyRyTbDJTpzjTKcg=s64","userId":"00918429620522674110"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["inputs_num = xtrain.shape[1] * xtrain.shape[2] #number of pixels = number of network inputs\n","xtrain = xtrain.reshape(xtrain.shape[0], inputs_num).astype('float32')\n","xtest = xtest.reshape(xtest.shape[0], inputs_num).astype('float32')\n","\n","# normalize inputs from 0-255 to 0-1\n","xtrain = xtrain / 255\n","xtest = xtest / 255\n","\n","print(xtrain.shape)\n","print(xtest.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(60000, 784)\n","(10000, 784)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u7HZhMAFUco9","colab_type":"text"},"source":["### Coding of class information (requested responses from 10 output neurons)"]},{"cell_type":"code","metadata":{"id":"LRwm8ZOJUcpB","colab_type":"code","outputId":"f2a47433-bf09-4ba9-c0b6-a40c83072c40","executionInfo":{"status":"ok","timestamp":1580293243047,"user_tz":-60,"elapsed":8486,"user":{"displayName":"Miguel Fernández","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_ckDCkb0V8ABako_2n9-az8dxyRyTbDJTpzjTKcg=s64","userId":"00918429620522674110"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["ytrain = np_utils.to_categorical(ytrain)\n","ytest = np_utils.to_categorical(ytest)\n","num_classes = ytest.shape[1]\n","print(ytest.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(10000, 10)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Jf2EdcJrUcpH","colab_type":"text"},"source":["### Defining and compiling the model"]},{"cell_type":"code","metadata":{"id":"VsJNhvtTUcpI","colab_type":"code","outputId":"29ff1080-3213-4bf7-b76e-0bd1183a8211","executionInfo":{"status":"ok","timestamp":1580293243049,"user_tz":-60,"elapsed":8476,"user":{"displayName":"Miguel Fernández","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_ckDCkb0V8ABako_2n9-az8dxyRyTbDJTpzjTKcg=s64","userId":"00918429620522674110"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["model = Sequential()\n","model.add(Dense(500, input_dim=inputs_num, kernel_initializer='normal', activation='relu'))\n","model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xj0GSflCUcpL","colab_type":"text"},"source":["### Saving the best model to a file\n","\n","During the learning process, we can monitor selected metrics and save current network models to the file. This is useful for big problems, when network learning takes a very long time and loss of results in case of failure is an unpleasant experience.\n","\n","In the following example, we monitor the quality of the classification on the validation set and save the model to the file, as long as it is better than any earlier (i.e., from earlier epochs)."]},{"cell_type":"code","metadata":{"id":"43NZzvPPUcpL","colab_type":"code","colab":{}},"source":["logger = keras.callbacks.ModelCheckpoint('mnist_model_MLP.hdf5', monitor='val_acc', verbose=0, save_best_only=True)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZPeYiVZvUcpO","colab_type":"code","outputId":"72a7349f-7907-47e2-ee86-0150ae7e960a","executionInfo":{"status":"ok","timestamp":1580293273953,"user_tz":-60,"elapsed":39358,"user":{"displayName":"Miguel Fernández","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_ckDCkb0V8ABako_2n9-az8dxyRyTbDJTpzjTKcg=s64","userId":"00918429620522674110"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.fit(xtrain, ytrain, validation_data=(xtest, ytest), epochs=20, batch_size=200, verbose=2, callbacks=[logger])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Train on 60000 samples, validate on 10000 samples\n","Epoch 1/20\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n"," - 11s - loss: 0.3159 - acc: 0.9122 - val_loss: 0.1622 - val_acc: 0.9517\n","Epoch 2/20\n"," - 1s - loss: 0.1295 - acc: 0.9628 - val_loss: 0.1041 - val_acc: 0.9695\n","Epoch 3/20\n"," - 1s - loss: 0.0864 - acc: 0.9751 - val_loss: 0.0871 - val_acc: 0.9742\n","Epoch 4/20\n"," - 1s - loss: 0.0624 - acc: 0.9823 - val_loss: 0.0732 - val_acc: 0.9789\n","Epoch 5/20\n"," - 1s - loss: 0.0460 - acc: 0.9869 - val_loss: 0.0663 - val_acc: 0.9794\n","Epoch 6/20\n"," - 1s - loss: 0.0355 - acc: 0.9905 - val_loss: 0.0682 - val_acc: 0.9786\n","Epoch 7/20\n"," - 1s - loss: 0.0271 - acc: 0.9926 - val_loss: 0.0609 - val_acc: 0.9792\n","Epoch 8/20\n"," - 1s - loss: 0.0212 - acc: 0.9948 - val_loss: 0.0596 - val_acc: 0.9819\n","Epoch 9/20\n"," - 1s - loss: 0.0160 - acc: 0.9965 - val_loss: 0.0583 - val_acc: 0.9818\n","Epoch 10/20\n"," - 1s - loss: 0.0129 - acc: 0.9973 - val_loss: 0.0613 - val_acc: 0.9809\n","Epoch 11/20\n"," - 1s - loss: 0.0103 - acc: 0.9981 - val_loss: 0.0610 - val_acc: 0.9813\n","Epoch 12/20\n"," - 1s - loss: 0.0078 - acc: 0.9987 - val_loss: 0.0595 - val_acc: 0.9813\n","Epoch 13/20\n"," - 1s - loss: 0.0060 - acc: 0.9991 - val_loss: 0.0602 - val_acc: 0.9824\n","Epoch 14/20\n"," - 1s - loss: 0.0048 - acc: 0.9993 - val_loss: 0.0637 - val_acc: 0.9816\n","Epoch 15/20\n"," - 1s - loss: 0.0042 - acc: 0.9995 - val_loss: 0.0615 - val_acc: 0.9821\n","Epoch 16/20\n"," - 1s - loss: 0.0029 - acc: 0.9998 - val_loss: 0.0654 - val_acc: 0.9823\n","Epoch 17/20\n"," - 1s - loss: 0.0019 - acc: 0.9999 - val_loss: 0.0618 - val_acc: 0.9832\n","Epoch 18/20\n"," - 1s - loss: 0.0016 - acc: 0.9999 - val_loss: 0.0661 - val_acc: 0.9823\n","Epoch 19/20\n"," - 1s - loss: 0.0138 - acc: 0.9955 - val_loss: 0.0772 - val_acc: 0.9796\n","Epoch 20/20\n"," - 1s - loss: 0.0066 - acc: 0.9982 - val_loss: 0.0741 - val_acc: 0.9803\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f161dd18e10>"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"qmkZ6dF1UcpW","colab_type":"text"},"source":["### Evaluation of the final and best model"]},{"cell_type":"code","metadata":{"id":"EsxAfCNdUcpX","colab_type":"code","outputId":"9fbf284d-0a3c-4c0c-dec4-591d22dd6df2","executionInfo":{"status":"ok","timestamp":1580293275168,"user_tz":-60,"elapsed":40555,"user":{"displayName":"Miguel Fernández","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_ckDCkb0V8ABako_2n9-az8dxyRyTbDJTpzjTKcg=s64","userId":"00918429620522674110"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["scores = model.evaluate(xtest, ytest, verbose=0)\n","print(\"Test error: %.2f%%\" % (100-scores[1]*100))\n","\n","#reading the best model from file\n","model2 = load_model('mnist_model_MLP.hdf5')\n","scores2 = model2.evaluate(xtest, ytest, batch_size=200)\n","print('network from file:')\n","print(\"Test error: %.2f%%\" % (100-scores2[1]*100))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test error: 1.97%\n","10000/10000 [==============================] - 0s 12us/step\n","network from file:\n","Test error: 1.68%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PmgfKzKpUcpd","colab_type":"text"},"source":["## The best results for MNIST \n","\n","How does our result compare the the best ones?\n","\n","http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354"]},{"cell_type":"markdown","metadata":{"id":"J7xTHrzTUcpj","colab_type":"text"},"source":["## Convolutional networks\n","\n","Currently, some of the best models for image analysis are convolutional networks.\n","\n","The basis of their functioning are:\n","\n","- convolutional layers (sharing weights between neurons)\n","- MaxPooling layers (reduction of the dimensionality of the problem)\n","- ReLU type activation functions\n","- regularization, e.g. by the Dropout method\n","\n","A popular model is a convolutional network in which a number of convolutional layers with ReLU activation functions alternate with MaxPooling layers. After that one or more layers of the MLP type follows (the designation FC means' Fully Connected`).\n","\n","Often, there are layers implementing the Dropout type of regularization strategies, which are supposed to counteract the over-fitting of the model.\n","\n","The following pictures are from http://cs231n.github.io/convolutional-networks/\n","\n","![image.png](attachment:image.png)"]},{"cell_type":"markdown","metadata":{"id":"e4-34ez5Ucpl","colab_type":"text"},"source":["###  ReLU activation function\n","\n","https://en.wikipedia.org/wiki/Rectifier_(neural_networks)\n","\n","![image.png](attachment:image.png)"]},{"cell_type":"markdown","metadata":{"id":"8iiQocN2Ucpm","colab_type":"text"},"source":["![image.png](attachment:image.png)"]},{"cell_type":"markdown","metadata":{"id":"R3pIEtZ6Ucpo","colab_type":"text"},"source":["### Convolutional layers\n","\n","The convolutional layer is a set of filters (neurons) that scan all channels of the input image (three in the example below). Scanning means that the weights of the same neuron are used repeatedly, which reduces the number of neurons needed.\n","\n","The following example has two 3x3 filters, so the output of this convolutionary layer will be a new image with two channels (Output Volume)."]},{"cell_type":"markdown","metadata":{"id":"5g3TMudUUcpp","colab_type":"text"},"source":["![image.png](attachment:image.png)"]},{"cell_type":"markdown","metadata":{"id":"RejZk_k9Ucpq","colab_type":"text"},"source":["![image.png](attachment:image.png)"]},{"cell_type":"markdown","metadata":{"id":"cZGeWBuZUcpr","colab_type":"text"},"source":["###  Max Pooling Layers\n","\n","The Max Pooling layers are designed to limit the dimensionality of data transferred to subsequent layers. From each selected area (eg 2x2 pixels), the maximum value is selected.\n","\n","Please note that pooling does not change the \"depth\" (number of channels).\n","\n","For example:\n","\n","![image.png](attachment:image.png)"]},{"cell_type":"markdown","metadata":{"id":"8MtjnzJQUcpt","colab_type":"text"},"source":["## Implementation of a simple convolutional network with Keras \n","\n","The designed network will have only one convolutional layer, followed by one hidden MLP layer. The output of the entire network will be another layer of the `softmax` type.\n"]},{"cell_type":"markdown","metadata":{"id":"gzqWnemuUcpu","colab_type":"text"},"source":["### Imports and data loading"]},{"cell_type":"code","metadata":{"id":"GUc39pjEUcpv","colab_type":"code","outputId":"a08ae0a3-ea76-46d9-e6a0-15e62168ae4b","executionInfo":{"status":"ok","timestamp":1580293275448,"user_tz":-60,"elapsed":40804,"user":{"displayName":"Miguel Fernández","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_ckDCkb0V8ABako_2n9-az8dxyRyTbDJTpzjTKcg=s64","userId":"00918429620522674110"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["import tensorflow as tf\n","import numpy as np\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import Flatten\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.models import load_model\n","from keras.utils import np_utils\n","\n","#import os\n","#path = '.'\n","#os.chdir(path)\n","\n","print(tf.__version__)\n","print(keras.__version__)\n","\n","(xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n","print('xtrain.shape',xtrain.shape)\n","print('ytrain.shape',ytrain.shape)\n","print('xtest.shape',xtest.shape)\n","print('ytest.shape',ytest.shape)\n","\n","\n","seed = 12345\n","np.random.seed(seed)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.15.0\n","2.2.5\n","xtrain.shape (60000, 28, 28)\n","ytrain.shape (60000,)\n","xtest.shape (10000, 28, 28)\n","ytest.shape (10000,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MlosY0U-Ucp4","colab_type":"text"},"source":["### Data preparation\n","\n","Please note that the network inputs are now images, not one-dimensional data. The convolutional layer expects data with the dimensions `(width, height, number of channels)`. In our MNIST example, the images are 28x28x1 (one channel, monochrome images).\n","\n","Please note the appropriate use of the `reshape` function.\n","\n","It is also possible to use the input data in the form `(number of channels, width, height)`"]},{"cell_type":"code","metadata":{"id":"ZuTP7EGVUcp5","colab_type":"code","colab":{}},"source":["xtrain = xtrain.reshape(xtrain.shape[0], 28, 28, 1).astype('float32')\n","xtest = xtest.reshape(xtest.shape[0], 28, 28, 1).astype('float32')\n","\n","# normalize inputs from 0-255 to 0-1\n","xtrain = xtrain / 255\n","xtest = xtest / 255\n","\n","# one hot encode outputs\n","ytrain = np_utils.to_categorical(ytrain)\n","ytest = np_utils.to_categorical(ytest)\n","num_classes = ytest.shape[1]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m73PcgPqUcp8","colab_type":"text"},"source":["### Defining and compiling the model\n","\n","The first layer is a convolution layer consisting of 32 filters with a size of 5x5 and a ReLU activation function.\n","\n","Please note that it was given directly\n","\n","`data_format='channel_last'`\n","\n","that is, data should have the format `(width, height, number of channels)`, in this example 28x28x1.\n","\n","The `Flatten` layer converts multidimensional data into one-dimensional, so that it can be used as another layer of MLP.\n","\n","The `Dropout (0.2)` layer means that each time 20% of random neurons will be excluded from network activity. This is to prevent the network from overfitting."]},{"cell_type":"code","metadata":{"id":"B-gDnWADUcp9","colab_type":"code","outputId":"4e129acd-fcf2-44d3-c54e-4ca784ec1747","executionInfo":{"status":"ok","timestamp":1580293275692,"user_tz":-60,"elapsed":40999,"user":{"displayName":"Miguel Fernández","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_ckDCkb0V8ABako_2n9-az8dxyRyTbDJTpzjTKcg=s64","userId":"00918429620522674110"}},"colab":{"base_uri":"https://localhost:8080/","height":190}},"source":["model = Sequential()\n","model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu', data_format='channels_last'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.2))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6Y8Q9v3tUcqA","colab_type":"text"},"source":["### Training\n"]},{"cell_type":"code","metadata":{"id":"COuC1Ys0UcqC","colab_type":"code","outputId":"a135257d-2d71-4406-c59a-876975558494","executionInfo":{"status":"ok","timestamp":1580293315824,"user_tz":-60,"elapsed":81108,"user":{"displayName":"Miguel Fernández","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_ckDCkb0V8ABako_2n9-az8dxyRyTbDJTpzjTKcg=s64","userId":"00918429620522674110"}},"colab":{"base_uri":"https://localhost:8080/","height":731}},"source":["logger = keras.callbacks.ModelCheckpoint('mnist_model_CONV_SIMPLE.hdf5', monitor='val_acc', verbose=0, save_best_only=True)\n","\n","# Fit the model\n","model.fit(xtrain, ytrain, validation_data=(xtest, ytest), epochs=20, batch_size=200, verbose=2, callbacks=[logger])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/20\n"," - 7s - loss: 0.2493 - acc: 0.9276 - val_loss: 0.0864 - val_acc: 0.9739\n","Epoch 2/20\n"," - 2s - loss: 0.0769 - acc: 0.9774 - val_loss: 0.0471 - val_acc: 0.9850\n","Epoch 3/20\n"," - 2s - loss: 0.0541 - acc: 0.9836 - val_loss: 0.0453 - val_acc: 0.9854\n","Epoch 4/20\n"," - 2s - loss: 0.0436 - acc: 0.9867 - val_loss: 0.0384 - val_acc: 0.9873\n","Epoch 5/20\n"," - 2s - loss: 0.0348 - acc: 0.9888 - val_loss: 0.0333 - val_acc: 0.9891\n","Epoch 6/20\n"," - 2s - loss: 0.0283 - acc: 0.9917 - val_loss: 0.0316 - val_acc: 0.9897\n","Epoch 7/20\n"," - 2s - loss: 0.0231 - acc: 0.9923 - val_loss: 0.0367 - val_acc: 0.9874\n","Epoch 8/20\n"," - 2s - loss: 0.0197 - acc: 0.9940 - val_loss: 0.0357 - val_acc: 0.9886\n","Epoch 9/20\n"," - 2s - loss: 0.0158 - acc: 0.9951 - val_loss: 0.0296 - val_acc: 0.9910\n","Epoch 10/20\n"," - 2s - loss: 0.0147 - acc: 0.9952 - val_loss: 0.0308 - val_acc: 0.9911\n","Epoch 11/20\n"," - 2s - loss: 0.0135 - acc: 0.9956 - val_loss: 0.0307 - val_acc: 0.9899\n","Epoch 12/20\n"," - 2s - loss: 0.0112 - acc: 0.9965 - val_loss: 0.0362 - val_acc: 0.9889\n","Epoch 13/20\n"," - 2s - loss: 0.0102 - acc: 0.9967 - val_loss: 0.0317 - val_acc: 0.9906\n","Epoch 14/20\n"," - 2s - loss: 0.0092 - acc: 0.9973 - val_loss: 0.0317 - val_acc: 0.9901\n","Epoch 15/20\n"," - 2s - loss: 0.0082 - acc: 0.9973 - val_loss: 0.0370 - val_acc: 0.9900\n","Epoch 16/20\n"," - 2s - loss: 0.0078 - acc: 0.9975 - val_loss: 0.0355 - val_acc: 0.9907\n","Epoch 17/20\n"," - 2s - loss: 0.0068 - acc: 0.9980 - val_loss: 0.0357 - val_acc: 0.9892\n","Epoch 18/20\n"," - 2s - loss: 0.0068 - acc: 0.9978 - val_loss: 0.0391 - val_acc: 0.9902\n","Epoch 19/20\n"," - 2s - loss: 0.0057 - acc: 0.9982 - val_loss: 0.0379 - val_acc: 0.9899\n","Epoch 20/20\n"," - 2s - loss: 0.0048 - acc: 0.9986 - val_loss: 0.0350 - val_acc: 0.9909\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f15fe7cd3c8>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"yzQGJNwOUcqH","colab_type":"text"},"source":["### Testing"]},{"cell_type":"code","metadata":{"id":"4ENzua1RUcqI","colab_type":"code","outputId":"7b8e2710-5a64-4b07-a6e8-cde40aceee5b","executionInfo":{"status":"ok","timestamp":1580293317182,"user_tz":-60,"elapsed":82435,"user":{"displayName":"Miguel Fernández","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_ckDCkb0V8ABako_2n9-az8dxyRyTbDJTpzjTKcg=s64","userId":"00918429620522674110"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["scores = model.evaluate(xtest, ytest, verbose=0)\n","print(\"Test error: %.2f%%\" % (100-scores[1]*100))\n","\n","#Best model\n","model2 = load_model('mnist_model_CONV_SIMPLE.hdf5')\n","scores2 = model2.evaluate(xtest, ytest, batch_size=200)\n","print('The best network from file:')\n","print(\"Test error: %.2f%%\" % (100-scores2[1]*100))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test error: 0.91%\n","10000/10000 [==============================] - 0s 19us/step\n","The best network from file:\n","Test error: 0.89%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RlHMjlmGUcqK","colab_type":"text"},"source":["## A bigger convolutional network\n","\n","Compare previous results with the results of the following network. Read its architecture."]},{"cell_type":"code","metadata":{"id":"veCWrhmpUcqL","colab_type":"code","outputId":"20edd7b2-4c7f-4b87-8ed8-046c470875d1","executionInfo":{"status":"ok","timestamp":1580293357909,"user_tz":-60,"elapsed":123124,"user":{"displayName":"Miguel Fernández","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_ckDCkb0V8ABako_2n9-az8dxyRyTbDJTpzjTKcg=s64","userId":"00918429620522674110"}},"colab":{"base_uri":"https://localhost:8080/","height":901}},"source":["import tensorflow as tf\n","import numpy as np\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import Flatten\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.models import load_model\n","from keras.utils import np_utils\n","\n","#import os\n","#path = '.'\n","#os.chdir(path)\n","\n","print(tf.__version__)\n","print(keras.__version__)\n","\n","(xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n","print('xtrain.shape',xtrain.shape)\n","print('ytrain.shape',ytrain.shape)\n","print('xtest.shape',xtest.shape)\n","print('ytest.shape',ytest.shape)\n","\n","# fix random seed\n","seed = 12345\n","np.random.seed(seed)\n","\n","\n","xtrain = xtrain.reshape(xtrain.shape[0], 28, 28, 1).astype('float32')\n","xtest = xtest.reshape(xtest.shape[0], 28, 28, 1).astype('float32')\n","\n","# normalize inputs from 0-255 to 0-1\n","xtrain = xtrain / 255\n","xtest = xtest / 255\n","\n","# one hot encode outputs\n","ytrain = np_utils.to_categorical(ytrain)\n","ytest = np_utils.to_categorical(ytest)\n","num_classes = ytest.shape[1]\n","\n","# define model\n","model = Sequential()\n","model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(15, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.2))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(50, activation='relu'))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","logger = keras.callbacks.ModelCheckpoint('mnist_model_CONV_BIGGER.hdf5', monitor='val_acc', verbose=0, save_best_only=True)\n","\n","# Fit the model\n","model.fit(xtrain, ytrain, validation_data=(xtest, ytest), epochs=20, batch_size=200, verbose=2, callbacks=[logger])\n","\n","# Final evaluation of the model\n","scores = model.evaluate(xtest, ytest, verbose=0)\n","print(\"Test error: %.2f%%\" % (100-scores[1]*100))\n","\n","#Best model\n","model2 = load_model('mnist_model_CONV_BIGGER.hdf5')\n","scores2 = model2.evaluate(xtest, ytest, batch_size=200)\n","print('The best network from the file:')\n","print(\"Test error: %.2f%%\" % (100-scores2[1]*100))\n","\n","print('end')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.15.0\n","2.2.5\n","xtrain.shape (60000, 28, 28)\n","ytrain.shape (60000,)\n","xtest.shape (10000, 28, 28)\n","ytest.shape (10000,)\n","Train on 60000 samples, validate on 10000 samples\n","Epoch 1/20\n"," - 3s - loss: 0.3860 - acc: 0.8786 - val_loss: 0.0824 - val_acc: 0.9735\n","Epoch 2/20\n"," - 2s - loss: 0.0972 - acc: 0.9702 - val_loss: 0.0504 - val_acc: 0.9844\n","Epoch 3/20\n"," - 2s - loss: 0.0675 - acc: 0.9789 - val_loss: 0.0376 - val_acc: 0.9889\n","Epoch 4/20\n"," - 2s - loss: 0.0564 - acc: 0.9827 - val_loss: 0.0302 - val_acc: 0.9911\n","Epoch 5/20\n"," - 2s - loss: 0.0462 - acc: 0.9851 - val_loss: 0.0275 - val_acc: 0.9919\n","Epoch 6/20\n"," - 2s - loss: 0.0410 - acc: 0.9870 - val_loss: 0.0233 - val_acc: 0.9927\n","Epoch 7/20\n"," - 2s - loss: 0.0353 - acc: 0.9890 - val_loss: 0.0292 - val_acc: 0.9908\n","Epoch 8/20\n"," - 2s - loss: 0.0323 - acc: 0.9897 - val_loss: 0.0255 - val_acc: 0.9909\n","Epoch 9/20\n"," - 2s - loss: 0.0304 - acc: 0.9899 - val_loss: 0.0228 - val_acc: 0.9929\n","Epoch 10/20\n"," - 2s - loss: 0.0283 - acc: 0.9907 - val_loss: 0.0233 - val_acc: 0.9922\n","Epoch 11/20\n"," - 2s - loss: 0.0264 - acc: 0.9915 - val_loss: 0.0231 - val_acc: 0.9921\n","Epoch 12/20\n"," - 2s - loss: 0.0234 - acc: 0.9928 - val_loss: 0.0224 - val_acc: 0.9929\n","Epoch 13/20\n"," - 2s - loss: 0.0234 - acc: 0.9920 - val_loss: 0.0211 - val_acc: 0.9932\n","Epoch 14/20\n"," - 2s - loss: 0.0212 - acc: 0.9929 - val_loss: 0.0220 - val_acc: 0.9931\n","Epoch 15/20\n"," - 2s - loss: 0.0209 - acc: 0.9932 - val_loss: 0.0238 - val_acc: 0.9930\n","Epoch 16/20\n"," - 2s - loss: 0.0187 - acc: 0.9935 - val_loss: 0.0224 - val_acc: 0.9923\n","Epoch 17/20\n"," - 2s - loss: 0.0187 - acc: 0.9932 - val_loss: 0.0215 - val_acc: 0.9926\n","Epoch 18/20\n"," - 2s - loss: 0.0175 - acc: 0.9940 - val_loss: 0.0234 - val_acc: 0.9933\n","Epoch 19/20\n"," - 2s - loss: 0.0174 - acc: 0.9942 - val_loss: 0.0251 - val_acc: 0.9926\n","Epoch 20/20\n"," - 2s - loss: 0.0153 - acc: 0.9949 - val_loss: 0.0255 - val_acc: 0.9920\n","Test error: 0.80%\n","10000/10000 [==============================] - 0s 26us/step\n","The best network from the file:\n","Test error: 0.67%\n","end\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"q0ZNpNtcUcqN","colab_type":"text"},"source":["## Comparing the models\n","\n","In case of problems with training, attached files\n","\n","- `_mnist_model_MLP.hdf5`\n","- `_mnist_model_CONV_SIMPLE.hdf5`\n","- `_mnist_model_CONV_BIGGER.hdf5`\n","\n","contain previously trained models.\n","\n","Use the following script to compare their actions. How far are these models from the best known?"]},{"cell_type":"code","metadata":{"id":"EiFYPQsRUcqO","colab_type":"code","outputId":"ea2124fa-c39a-48f1-d431-e481c60eaa99","executionInfo":{"status":"ok","timestamp":1580293363421,"user_tz":-60,"elapsed":128619,"user":{"displayName":"Miguel Fernández","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_ckDCkb0V8ABako_2n9-az8dxyRyTbDJTpzjTKcg=s64","userId":"00918429620522674110"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["import tensorflow as tf\n","import numpy as np\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import Flatten\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.models import load_model\n","from keras.utils import np_utils\n","\n","#import os\n","#path = '.'\n","#os.chdir(path)\n","\n","print(tf.__version__)\n","print(keras.__version__)\n","\n","(xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n","print('xtrain.shape',xtrain.shape)\n","print('ytrain.shape',ytrain.shape)\n","print('xtest.shape',xtest.shape)\n","print('ytest.shape',ytest.shape)\n","\n","xtrain = xtrain.reshape(xtrain.shape[0], 784).astype('float32')\n","xtest = xtest.reshape(xtest.shape[0], 784).astype('float32')\n","\n","# normalize inputs from 0-255 to 0-1\n","xtrain = xtrain / 255\n","xtest = xtest / 255\n","\n","# one hot encode outputs\n","ytrain = np_utils.to_categorical(ytrain)\n","ytest = np_utils.to_categorical(ytest)\n","\n","#Compare the networks\n","\n","#MLP\n","model = load_model('mnist_model_MLP.hdf5')\n","scores = model.evaluate(xtest, ytest, batch_size=200)\n","print(\"Test error (Model MLP): %.2f%%\" % (100-scores[1]*100))\n","\n","\n","xtrain = xtrain.reshape(xtrain.shape[0], 28, 28, 1).astype('float32')\n","xtest = xtest.reshape(xtest.shape[0], 28, 28, 1).astype('float32')\n","\n","#Smaller conv net\n","model = load_model('mnist_model_CONV_SIMPLE.hdf5')\n","scores = model.evaluate(xtest, ytest, batch_size=200)\n","print(\"Test error (Model CONV SIMPLE): %.2f%%\" % (100-scores[1]*100))\n","\n","#Bigger conv net\n","model = load_model('mnist_model_CONV_BIGGER.hdf5')\n","scores = model.evaluate(xtest, ytest, batch_size=200)\n","print(\"Test error (Model CONV BIGGER): %.2f%%\" % (100-scores[1]*100))\n","\n","print('end')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.15.0\n","2.2.5\n","xtrain.shape (60000, 28, 28)\n","ytrain.shape (60000,)\n","xtest.shape (10000, 28, 28)\n","ytest.shape (10000,)\n","10000/10000 [==============================] - 0s 23us/step\n","Test error (Model MLP): 1.68%\n","10000/10000 [==============================] - 0s 29us/step\n","Test error (Model CONV SIMPLE): 0.89%\n","10000/10000 [==============================] - 0s 32us/step\n","Test error (Model CONV BIGGER): 0.67%\n","end\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RkYKVifcUcqQ","colab_type":"text"},"source":["### Task 1\n","\n","- Prepare and train a convolutional neural network on CIFAR-10 database. \n","- Try different architectures of networks\n","- Compare and report the results\n"]},{"cell_type":"markdown","metadata":{"id":"r7FkicKiUcqR","colab_type":"text"},"source":["#### YOUR DESCRIPTION AND COMMENTS"]},{"cell_type":"markdown","metadata":{"id":"hEEC8zDmTo69","colab_type":"text"},"source":["### **Getting CIFAR-10**"]},{"cell_type":"code","metadata":{"id":"udUEY9TcUcqS","colab_type":"code","outputId":"ee2916b0-44e8-4ec8-d50b-a53248ba377d","executionInfo":{"status":"ok","timestamp":1580293367242,"user_tz":-60,"elapsed":132425,"user":{"displayName":"Miguel Fernández","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_ckDCkb0V8ABako_2n9-az8dxyRyTbDJTpzjTKcg=s64","userId":"00918429620522674110"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["%matplotlib notebook\n","import tensorflow as tf\n","import keras as krs\n","import numpy as np\n","\n","from keras.datasets import cifar10\n","import matplotlib.pyplot as plt\n","\n","(xtrain, ytrain), (xtest, ytest) = cifar10.load_data()\n","print('xtrain.shape',xtrain.shape)\n","print('ytrain.shape',ytrain.shape)\n","print('xtest.shape',xtest.shape)\n","print('ytest.shape',ytest.shape)\n","\n","#wyswietlenie pierwszego przykladu\n","plt.imshow(xtest[0,:,:], cmap=plt.get_cmap('gray'))\n","\n","#Wyswietlenie kilku pierwszych przykladow\n","rows = 8\n","cols = 10\n","counter = 0\n","\n","images = None\n","\n","for i in range(rows):\n","    current_row = None\n","    for j in range(cols):\n","        im = xtest[counter,:,:]\n","        counter = counter + 1\n","        if current_row is None:\n","            current_row = im\n","        else:\n","            current_row = np.hstack((current_row, im))\n","    if images is None:\n","        images = current_row\n","    else:\n","        images = np.vstack((images, current_row))\n","        \n","plt.figure()\n","plt.imshow(images, cmap=plt.get_cmap('gray'))\n","\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 2s 0us/step\n","xtrain.shape (50000, 32, 32, 3)\n","ytrain.shape (50000, 1)\n","xtest.shape (10000, 32, 32, 3)\n","ytest.shape (10000, 1)\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/javascript":["/* Put everything inside the global mpl namespace */\n","window.mpl = {};\n","\n","\n","mpl.get_websocket_type = function() {\n","    if (typeof(WebSocket) !== 'undefined') {\n","        return WebSocket;\n","    } else if (typeof(MozWebSocket) !== 'undefined') {\n","        return MozWebSocket;\n","    } else {\n","        alert('Your browser does not have WebSocket support. ' +\n","              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n","              'Firefox 4 and 5 are also supported but you ' +\n","              'have to enable WebSockets in about:config.');\n","    };\n","}\n","\n","mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n","    this.id = figure_id;\n","\n","    this.ws = websocket;\n","\n","    this.supports_binary = (this.ws.binaryType != undefined);\n","\n","    if (!this.supports_binary) {\n","        var warnings = document.getElementById(\"mpl-warnings\");\n","        if (warnings) {\n","            warnings.style.display = 'block';\n","            warnings.textContent = (\n","                \"This browser does not support binary websocket messages. \" +\n","                    \"Performance may be slow.\");\n","        }\n","    }\n","\n","    this.imageObj = new Image();\n","\n","    this.context = undefined;\n","    this.message = undefined;\n","    this.canvas = undefined;\n","    this.rubberband_canvas = undefined;\n","    this.rubberband_context = undefined;\n","    this.format_dropdown = undefined;\n","\n","    this.image_mode = 'full';\n","\n","    this.root = $('<div/>');\n","    this._root_extra_style(this.root)\n","    this.root.attr('style', 'display: inline-block');\n","\n","    $(parent_element).append(this.root);\n","\n","    this._init_header(this);\n","    this._init_canvas(this);\n","    this._init_toolbar(this);\n","\n","    var fig = this;\n","\n","    this.waiting = false;\n","\n","    this.ws.onopen =  function () {\n","            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n","            fig.send_message(\"send_image_mode\", {});\n","            if (mpl.ratio != 1) {\n","                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n","            }\n","            fig.send_message(\"refresh\", {});\n","        }\n","\n","    this.imageObj.onload = function() {\n","            if (fig.image_mode == 'full') {\n","                // Full images could contain transparency (where diff images\n","                // almost always do), so we need to clear the canvas so that\n","                // there is no ghosting.\n","                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n","            }\n","            fig.context.drawImage(fig.imageObj, 0, 0);\n","        };\n","\n","    this.imageObj.onunload = function() {\n","        fig.ws.close();\n","    }\n","\n","    this.ws.onmessage = this._make_on_message_function(this);\n","\n","    this.ondownload = ondownload;\n","}\n","\n","mpl.figure.prototype._init_header = function() {\n","    var titlebar = $(\n","        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n","        'ui-helper-clearfix\"/>');\n","    var titletext = $(\n","        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n","        'text-align: center; padding: 3px;\"/>');\n","    titlebar.append(titletext)\n","    this.root.append(titlebar);\n","    this.header = titletext[0];\n","}\n","\n","\n","\n","mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n","\n","}\n","\n","\n","mpl.figure.prototype._root_extra_style = function(canvas_div) {\n","\n","}\n","\n","mpl.figure.prototype._init_canvas = function() {\n","    var fig = this;\n","\n","    var canvas_div = $('<div/>');\n","\n","    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n","\n","    function canvas_keyboard_event(event) {\n","        return fig.key_event(event, event['data']);\n","    }\n","\n","    canvas_div.keydown('key_press', canvas_keyboard_event);\n","    canvas_div.keyup('key_release', canvas_keyboard_event);\n","    this.canvas_div = canvas_div\n","    this._canvas_extra_style(canvas_div)\n","    this.root.append(canvas_div);\n","\n","    var canvas = $('<canvas/>');\n","    canvas.addClass('mpl-canvas');\n","    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n","\n","    this.canvas = canvas[0];\n","    this.context = canvas[0].getContext(\"2d\");\n","\n","    var backingStore = this.context.backingStorePixelRatio ||\n","\tthis.context.webkitBackingStorePixelRatio ||\n","\tthis.context.mozBackingStorePixelRatio ||\n","\tthis.context.msBackingStorePixelRatio ||\n","\tthis.context.oBackingStorePixelRatio ||\n","\tthis.context.backingStorePixelRatio || 1;\n","\n","    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n","\n","    var rubberband = $('<canvas/>');\n","    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n","\n","    var pass_mouse_events = true;\n","\n","    canvas_div.resizable({\n","        start: function(event, ui) {\n","            pass_mouse_events = false;\n","        },\n","        resize: function(event, ui) {\n","            fig.request_resize(ui.size.width, ui.size.height);\n","        },\n","        stop: function(event, ui) {\n","            pass_mouse_events = true;\n","            fig.request_resize(ui.size.width, ui.size.height);\n","        },\n","    });\n","\n","    function mouse_event_fn(event) {\n","        if (pass_mouse_events)\n","            return fig.mouse_event(event, event['data']);\n","    }\n","\n","    rubberband.mousedown('button_press', mouse_event_fn);\n","    rubberband.mouseup('button_release', mouse_event_fn);\n","    // Throttle sequential mouse events to 1 every 20ms.\n","    rubberband.mousemove('motion_notify', mouse_event_fn);\n","\n","    rubberband.mouseenter('figure_enter', mouse_event_fn);\n","    rubberband.mouseleave('figure_leave', mouse_event_fn);\n","\n","    canvas_div.on(\"wheel\", function (event) {\n","        event = event.originalEvent;\n","        event['data'] = 'scroll'\n","        if (event.deltaY < 0) {\n","            event.step = 1;\n","        } else {\n","            event.step = -1;\n","        }\n","        mouse_event_fn(event);\n","    });\n","\n","    canvas_div.append(canvas);\n","    canvas_div.append(rubberband);\n","\n","    this.rubberband = rubberband;\n","    this.rubberband_canvas = rubberband[0];\n","    this.rubberband_context = rubberband[0].getContext(\"2d\");\n","    this.rubberband_context.strokeStyle = \"#000000\";\n","\n","    this._resize_canvas = function(width, height) {\n","        // Keep the size of the canvas, canvas container, and rubber band\n","        // canvas in synch.\n","        canvas_div.css('width', width)\n","        canvas_div.css('height', height)\n","\n","        canvas.attr('width', width * mpl.ratio);\n","        canvas.attr('height', height * mpl.ratio);\n","        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n","\n","        rubberband.attr('width', width);\n","        rubberband.attr('height', height);\n","    }\n","\n","    // Set the figure to an initial 600x600px, this will subsequently be updated\n","    // upon first draw.\n","    this._resize_canvas(600, 600);\n","\n","    // Disable right mouse context menu.\n","    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n","        return false;\n","    });\n","\n","    function set_focus () {\n","        canvas.focus();\n","        canvas_div.focus();\n","    }\n","\n","    window.setTimeout(set_focus, 100);\n","}\n","\n","mpl.figure.prototype._init_toolbar = function() {\n","    var fig = this;\n","\n","    var nav_element = $('<div/>');\n","    nav_element.attr('style', 'width: 100%');\n","    this.root.append(nav_element);\n","\n","    // Define a callback function for later on.\n","    function toolbar_event(event) {\n","        return fig.toolbar_button_onclick(event['data']);\n","    }\n","    function toolbar_mouse_event(event) {\n","        return fig.toolbar_button_onmouseover(event['data']);\n","    }\n","\n","    for(var toolbar_ind in mpl.toolbar_items) {\n","        var name = mpl.toolbar_items[toolbar_ind][0];\n","        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n","        var image = mpl.toolbar_items[toolbar_ind][2];\n","        var method_name = mpl.toolbar_items[toolbar_ind][3];\n","\n","        if (!name) {\n","            // put a spacer in here.\n","            continue;\n","        }\n","        var button = $('<button/>');\n","        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n","                        'ui-button-icon-only');\n","        button.attr('role', 'button');\n","        button.attr('aria-disabled', 'false');\n","        button.click(method_name, toolbar_event);\n","        button.mouseover(tooltip, toolbar_mouse_event);\n","\n","        var icon_img = $('<span/>');\n","        icon_img.addClass('ui-button-icon-primary ui-icon');\n","        icon_img.addClass(image);\n","        icon_img.addClass('ui-corner-all');\n","\n","        var tooltip_span = $('<span/>');\n","        tooltip_span.addClass('ui-button-text');\n","        tooltip_span.html(tooltip);\n","\n","        button.append(icon_img);\n","        button.append(tooltip_span);\n","\n","        nav_element.append(button);\n","    }\n","\n","    var fmt_picker_span = $('<span/>');\n","\n","    var fmt_picker = $('<select/>');\n","    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n","    fmt_picker_span.append(fmt_picker);\n","    nav_element.append(fmt_picker_span);\n","    this.format_dropdown = fmt_picker[0];\n","\n","    for (var ind in mpl.extensions) {\n","        var fmt = mpl.extensions[ind];\n","        var option = $(\n","            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n","        fmt_picker.append(option);\n","    }\n","\n","    // Add hover states to the ui-buttons\n","    $( \".ui-button\" ).hover(\n","        function() { $(this).addClass(\"ui-state-hover\");},\n","        function() { $(this).removeClass(\"ui-state-hover\");}\n","    );\n","\n","    var status_bar = $('<span class=\"mpl-message\"/>');\n","    nav_element.append(status_bar);\n","    this.message = status_bar[0];\n","}\n","\n","mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n","    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n","    // which will in turn request a refresh of the image.\n","    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n","}\n","\n","mpl.figure.prototype.send_message = function(type, properties) {\n","    properties['type'] = type;\n","    properties['figure_id'] = this.id;\n","    this.ws.send(JSON.stringify(properties));\n","}\n","\n","mpl.figure.prototype.send_draw_message = function() {\n","    if (!this.waiting) {\n","        this.waiting = true;\n","        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n","    }\n","}\n","\n","\n","mpl.figure.prototype.handle_save = function(fig, msg) {\n","    var format_dropdown = fig.format_dropdown;\n","    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n","    fig.ondownload(fig, format);\n","}\n","\n","\n","mpl.figure.prototype.handle_resize = function(fig, msg) {\n","    var size = msg['size'];\n","    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n","        fig._resize_canvas(size[0], size[1]);\n","        fig.send_message(\"refresh\", {});\n","    };\n","}\n","\n","mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n","    var x0 = msg['x0'] / mpl.ratio;\n","    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n","    var x1 = msg['x1'] / mpl.ratio;\n","    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n","    x0 = Math.floor(x0) + 0.5;\n","    y0 = Math.floor(y0) + 0.5;\n","    x1 = Math.floor(x1) + 0.5;\n","    y1 = Math.floor(y1) + 0.5;\n","    var min_x = Math.min(x0, x1);\n","    var min_y = Math.min(y0, y1);\n","    var width = Math.abs(x1 - x0);\n","    var height = Math.abs(y1 - y0);\n","\n","    fig.rubberband_context.clearRect(\n","        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n","\n","    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n","}\n","\n","mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n","    // Updates the figure title.\n","    fig.header.textContent = msg['label'];\n","}\n","\n","mpl.figure.prototype.handle_cursor = function(fig, msg) {\n","    var cursor = msg['cursor'];\n","    switch(cursor)\n","    {\n","    case 0:\n","        cursor = 'pointer';\n","        break;\n","    case 1:\n","        cursor = 'default';\n","        break;\n","    case 2:\n","        cursor = 'crosshair';\n","        break;\n","    case 3:\n","        cursor = 'move';\n","        break;\n","    }\n","    fig.rubberband_canvas.style.cursor = cursor;\n","}\n","\n","mpl.figure.prototype.handle_message = function(fig, msg) {\n","    fig.message.textContent = msg['message'];\n","}\n","\n","mpl.figure.prototype.handle_draw = function(fig, msg) {\n","    // Request the server to send over a new figure.\n","    fig.send_draw_message();\n","}\n","\n","mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n","    fig.image_mode = msg['mode'];\n","}\n","\n","mpl.figure.prototype.updated_canvas_event = function() {\n","    // Called whenever the canvas gets updated.\n","    this.send_message(\"ack\", {});\n","}\n","\n","// A function to construct a web socket function for onmessage handling.\n","// Called in the figure constructor.\n","mpl.figure.prototype._make_on_message_function = function(fig) {\n","    return function socket_on_message(evt) {\n","        if (evt.data instanceof Blob) {\n","            /* FIXME: We get \"Resource interpreted as Image but\n","             * transferred with MIME type text/plain:\" errors on\n","             * Chrome.  But how to set the MIME type?  It doesn't seem\n","             * to be part of the websocket stream */\n","            evt.data.type = \"image/png\";\n","\n","            /* Free the memory for the previous frames */\n","            if (fig.imageObj.src) {\n","                (window.URL || window.webkitURL).revokeObjectURL(\n","                    fig.imageObj.src);\n","            }\n","\n","            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n","                evt.data);\n","            fig.updated_canvas_event();\n","            fig.waiting = false;\n","            return;\n","        }\n","        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n","            fig.imageObj.src = evt.data;\n","            fig.updated_canvas_event();\n","            fig.waiting = false;\n","            return;\n","        }\n","\n","        var msg = JSON.parse(evt.data);\n","        var msg_type = msg['type'];\n","\n","        // Call the  \"handle_{type}\" callback, which takes\n","        // the figure and JSON message as its only arguments.\n","        try {\n","            var callback = fig[\"handle_\" + msg_type];\n","        } catch (e) {\n","            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n","            return;\n","        }\n","\n","        if (callback) {\n","            try {\n","                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n","                callback(fig, msg);\n","            } catch (e) {\n","                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n","            }\n","        }\n","    };\n","}\n","\n","// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n","mpl.findpos = function(e) {\n","    //this section is from http://www.quirksmode.org/js/events_properties.html\n","    var targ;\n","    if (!e)\n","        e = window.event;\n","    if (e.target)\n","        targ = e.target;\n","    else if (e.srcElement)\n","        targ = e.srcElement;\n","    if (targ.nodeType == 3) // defeat Safari bug\n","        targ = targ.parentNode;\n","\n","    // jQuery normalizes the pageX and pageY\n","    // pageX,Y are the mouse positions relative to the document\n","    // offset() returns the position of the element relative to the document\n","    var x = e.pageX - $(targ).offset().left;\n","    var y = e.pageY - $(targ).offset().top;\n","\n","    return {\"x\": x, \"y\": y};\n","};\n","\n","/*\n"," * return a copy of an object with only non-object keys\n"," * we need this to avoid circular references\n"," * http://stackoverflow.com/a/24161582/3208463\n"," */\n","function simpleKeys (original) {\n","  return Object.keys(original).reduce(function (obj, key) {\n","    if (typeof original[key] !== 'object')\n","        obj[key] = original[key]\n","    return obj;\n","  }, {});\n","}\n","\n","mpl.figure.prototype.mouse_event = function(event, name) {\n","    var canvas_pos = mpl.findpos(event)\n","\n","    if (name === 'button_press')\n","    {\n","        this.canvas.focus();\n","        this.canvas_div.focus();\n","    }\n","\n","    var x = canvas_pos.x * mpl.ratio;\n","    var y = canvas_pos.y * mpl.ratio;\n","\n","    this.send_message(name, {x: x, y: y, button: event.button,\n","                             step: event.step,\n","                             guiEvent: simpleKeys(event)});\n","\n","    /* This prevents the web browser from automatically changing to\n","     * the text insertion cursor when the button is pressed.  We want\n","     * to control all of the cursor setting manually through the\n","     * 'cursor' event from matplotlib */\n","    event.preventDefault();\n","    return false;\n","}\n","\n","mpl.figure.prototype._key_event_extra = function(event, name) {\n","    // Handle any extra behaviour associated with a key event\n","}\n","\n","mpl.figure.prototype.key_event = function(event, name) {\n","\n","    // Prevent repeat events\n","    if (name == 'key_press')\n","    {\n","        if (event.which === this._key)\n","            return;\n","        else\n","            this._key = event.which;\n","    }\n","    if (name == 'key_release')\n","        this._key = null;\n","\n","    var value = '';\n","    if (event.ctrlKey && event.which != 17)\n","        value += \"ctrl+\";\n","    if (event.altKey && event.which != 18)\n","        value += \"alt+\";\n","    if (event.shiftKey && event.which != 16)\n","        value += \"shift+\";\n","\n","    value += 'k';\n","    value += event.which.toString();\n","\n","    this._key_event_extra(event, name);\n","\n","    this.send_message(name, {key: value,\n","                             guiEvent: simpleKeys(event)});\n","    return false;\n","}\n","\n","mpl.figure.prototype.toolbar_button_onclick = function(name) {\n","    if (name == 'download') {\n","        this.handle_save(this, null);\n","    } else {\n","        this.send_message(\"toolbar_button\", {name: name});\n","    }\n","};\n","\n","mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n","    this.message.textContent = tooltip;\n","};\n","mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n","\n","mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n","\n","mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n","    // Create a \"websocket\"-like object which calls the given IPython comm\n","    // object with the appropriate methods. Currently this is a non binary\n","    // socket, so there is still some room for performance tuning.\n","    var ws = {};\n","\n","    ws.close = function() {\n","        comm.close()\n","    };\n","    ws.send = function(m) {\n","        //console.log('sending', m);\n","        comm.send(m);\n","    };\n","    // Register the callback with on_msg.\n","    comm.on_msg(function(msg) {\n","        //console.log('receiving', msg['content']['data'], msg);\n","        // Pass the mpl event to the overridden (by mpl) onmessage function.\n","        ws.onmessage(msg['content']['data'])\n","    });\n","    return ws;\n","}\n","\n","mpl.mpl_figure_comm = function(comm, msg) {\n","    // This is the function which gets called when the mpl process\n","    // starts-up an IPython Comm through the \"matplotlib\" channel.\n","\n","    var id = msg.content.data.id;\n","    // Get hold of the div created by the display call when the Comm\n","    // socket was opened in Python.\n","    var element = $(\"#\" + id);\n","    var ws_proxy = comm_websocket_adapter(comm)\n","\n","    function ondownload(figure, format) {\n","        window.open(figure.imageObj.src);\n","    }\n","\n","    var fig = new mpl.figure(id, ws_proxy,\n","                           ondownload,\n","                           element.get(0));\n","\n","    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n","    // web socket which is closed, not our websocket->open comm proxy.\n","    ws_proxy.onopen();\n","\n","    fig.parent_element = element.get(0);\n","    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n","    if (!fig.cell_info) {\n","        console.error(\"Failed to find cell for figure\", id, fig);\n","        return;\n","    }\n","\n","    var output_index = fig.cell_info[2]\n","    var cell = fig.cell_info[0];\n","\n","};\n","\n","mpl.figure.prototype.handle_close = function(fig, msg) {\n","    var width = fig.canvas.width/mpl.ratio\n","    fig.root.unbind('remove')\n","\n","    // Update the output cell to use the data from the current canvas.\n","    fig.push_to_output();\n","    var dataURL = fig.canvas.toDataURL();\n","    // Re-enable the keyboard manager in IPython - without this line, in FF,\n","    // the notebook keyboard shortcuts fail.\n","    IPython.keyboard_manager.enable()\n","    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n","    fig.close_ws(fig, msg);\n","}\n","\n","mpl.figure.prototype.close_ws = function(fig, msg){\n","    fig.send_message('closing', msg);\n","    // fig.ws.close()\n","}\n","\n","mpl.figure.prototype.push_to_output = function(remove_interactive) {\n","    // Turn the data on the canvas into data in the output cell.\n","    var width = this.canvas.width/mpl.ratio\n","    var dataURL = this.canvas.toDataURL();\n","    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n","}\n","\n","mpl.figure.prototype.updated_canvas_event = function() {\n","    // Tell IPython that the notebook contents must change.\n","    IPython.notebook.set_dirty(true);\n","    this.send_message(\"ack\", {});\n","    var fig = this;\n","    // Wait a second, then push the new image to the DOM so\n","    // that it is saved nicely (might be nice to debounce this).\n","    setTimeout(function () { fig.push_to_output() }, 1000);\n","}\n","\n","mpl.figure.prototype._init_toolbar = function() {\n","    var fig = this;\n","\n","    var nav_element = $('<div/>');\n","    nav_element.attr('style', 'width: 100%');\n","    this.root.append(nav_element);\n","\n","    // Define a callback function for later on.\n","    function toolbar_event(event) {\n","        return fig.toolbar_button_onclick(event['data']);\n","    }\n","    function toolbar_mouse_event(event) {\n","        return fig.toolbar_button_onmouseover(event['data']);\n","    }\n","\n","    for(var toolbar_ind in mpl.toolbar_items){\n","        var name = mpl.toolbar_items[toolbar_ind][0];\n","        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n","        var image = mpl.toolbar_items[toolbar_ind][2];\n","        var method_name = mpl.toolbar_items[toolbar_ind][3];\n","\n","        if (!name) { continue; };\n","\n","        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n","        button.click(method_name, toolbar_event);\n","        button.mouseover(tooltip, toolbar_mouse_event);\n","        nav_element.append(button);\n","    }\n","\n","    // Add the status bar.\n","    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n","    nav_element.append(status_bar);\n","    this.message = status_bar[0];\n","\n","    // Add the close button to the window.\n","    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n","    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n","    button.click(function (evt) { fig.handle_close(fig, {}); } );\n","    button.mouseover('Stop Interaction', toolbar_mouse_event);\n","    buttongrp.append(button);\n","    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n","    titlebar.prepend(buttongrp);\n","}\n","\n","mpl.figure.prototype._root_extra_style = function(el){\n","    var fig = this\n","    el.on(\"remove\", function(){\n","\tfig.close_ws(fig, {});\n","    });\n","}\n","\n","mpl.figure.prototype._canvas_extra_style = function(el){\n","    // this is important to make the div 'focusable\n","    el.attr('tabindex', 0)\n","    // reach out to IPython and tell the keyboard manager to turn it's self\n","    // off when our div gets focus\n","\n","    // location in version 3\n","    if (IPython.notebook.keyboard_manager) {\n","        IPython.notebook.keyboard_manager.register_events(el);\n","    }\n","    else {\n","        // location in version 2\n","        IPython.keyboard_manager.register_events(el);\n","    }\n","\n","}\n","\n","mpl.figure.prototype._key_event_extra = function(event, name) {\n","    var manager = IPython.notebook.keyboard_manager;\n","    if (!manager)\n","        manager = IPython.keyboard_manager;\n","\n","    // Check for shift+enter\n","    if (event.shiftKey && event.which == 13) {\n","        this.canvas_div.blur();\n","        // select the cell after this one\n","        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n","        IPython.notebook.select(index + 1);\n","    }\n","}\n","\n","mpl.figure.prototype.handle_save = function(fig, msg) {\n","    fig.ondownload(fig, null);\n","}\n","\n","\n","mpl.find_output_cell = function(html_output) {\n","    // Return the cell and output element which can be found *uniquely* in the notebook.\n","    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n","    // IPython event is triggered only after the cells have been serialised, which for\n","    // our purposes (turning an active figure into a static one), is too late.\n","    var cells = IPython.notebook.get_cells();\n","    var ncells = cells.length;\n","    for (var i=0; i<ncells; i++) {\n","        var cell = cells[i];\n","        if (cell.cell_type === 'code'){\n","            for (var j=0; j<cell.output_area.outputs.length; j++) {\n","                var data = cell.output_area.outputs[j];\n","                if (data.data) {\n","                    // IPython >= 3 moved mimebundle to data attribute of output\n","                    data = data.data;\n","                }\n","                if (data['text/html'] == html_output) {\n","                    return [cell, data, j];\n","                }\n","            }\n","        }\n","    }\n","}\n","\n","// Register the function which deals with the matplotlib target/channel.\n","// The kernel may be null if the page has been refreshed.\n","if (IPython.notebook.kernel != null) {\n","    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n","}\n"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<div id='475e560b-7948-4ba8-910b-e07bf79bc12c'></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["/* Put everything inside the global mpl namespace */\n","window.mpl = {};\n","\n","\n","mpl.get_websocket_type = function() {\n","    if (typeof(WebSocket) !== 'undefined') {\n","        return WebSocket;\n","    } else if (typeof(MozWebSocket) !== 'undefined') {\n","        return MozWebSocket;\n","    } else {\n","        alert('Your browser does not have WebSocket support. ' +\n","              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n","              'Firefox 4 and 5 are also supported but you ' +\n","              'have to enable WebSockets in about:config.');\n","    };\n","}\n","\n","mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n","    this.id = figure_id;\n","\n","    this.ws = websocket;\n","\n","    this.supports_binary = (this.ws.binaryType != undefined);\n","\n","    if (!this.supports_binary) {\n","        var warnings = document.getElementById(\"mpl-warnings\");\n","        if (warnings) {\n","            warnings.style.display = 'block';\n","            warnings.textContent = (\n","                \"This browser does not support binary websocket messages. \" +\n","                    \"Performance may be slow.\");\n","        }\n","    }\n","\n","    this.imageObj = new Image();\n","\n","    this.context = undefined;\n","    this.message = undefined;\n","    this.canvas = undefined;\n","    this.rubberband_canvas = undefined;\n","    this.rubberband_context = undefined;\n","    this.format_dropdown = undefined;\n","\n","    this.image_mode = 'full';\n","\n","    this.root = $('<div/>');\n","    this._root_extra_style(this.root)\n","    this.root.attr('style', 'display: inline-block');\n","\n","    $(parent_element).append(this.root);\n","\n","    this._init_header(this);\n","    this._init_canvas(this);\n","    this._init_toolbar(this);\n","\n","    var fig = this;\n","\n","    this.waiting = false;\n","\n","    this.ws.onopen =  function () {\n","            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n","            fig.send_message(\"send_image_mode\", {});\n","            if (mpl.ratio != 1) {\n","                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n","            }\n","            fig.send_message(\"refresh\", {});\n","        }\n","\n","    this.imageObj.onload = function() {\n","            if (fig.image_mode == 'full') {\n","                // Full images could contain transparency (where diff images\n","                // almost always do), so we need to clear the canvas so that\n","                // there is no ghosting.\n","                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n","            }\n","            fig.context.drawImage(fig.imageObj, 0, 0);\n","        };\n","\n","    this.imageObj.onunload = function() {\n","        fig.ws.close();\n","    }\n","\n","    this.ws.onmessage = this._make_on_message_function(this);\n","\n","    this.ondownload = ondownload;\n","}\n","\n","mpl.figure.prototype._init_header = function() {\n","    var titlebar = $(\n","        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n","        'ui-helper-clearfix\"/>');\n","    var titletext = $(\n","        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n","        'text-align: center; padding: 3px;\"/>');\n","    titlebar.append(titletext)\n","    this.root.append(titlebar);\n","    this.header = titletext[0];\n","}\n","\n","\n","\n","mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n","\n","}\n","\n","\n","mpl.figure.prototype._root_extra_style = function(canvas_div) {\n","\n","}\n","\n","mpl.figure.prototype._init_canvas = function() {\n","    var fig = this;\n","\n","    var canvas_div = $('<div/>');\n","\n","    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n","\n","    function canvas_keyboard_event(event) {\n","        return fig.key_event(event, event['data']);\n","    }\n","\n","    canvas_div.keydown('key_press', canvas_keyboard_event);\n","    canvas_div.keyup('key_release', canvas_keyboard_event);\n","    this.canvas_div = canvas_div\n","    this._canvas_extra_style(canvas_div)\n","    this.root.append(canvas_div);\n","\n","    var canvas = $('<canvas/>');\n","    canvas.addClass('mpl-canvas');\n","    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n","\n","    this.canvas = canvas[0];\n","    this.context = canvas[0].getContext(\"2d\");\n","\n","    var backingStore = this.context.backingStorePixelRatio ||\n","\tthis.context.webkitBackingStorePixelRatio ||\n","\tthis.context.mozBackingStorePixelRatio ||\n","\tthis.context.msBackingStorePixelRatio ||\n","\tthis.context.oBackingStorePixelRatio ||\n","\tthis.context.backingStorePixelRatio || 1;\n","\n","    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n","\n","    var rubberband = $('<canvas/>');\n","    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n","\n","    var pass_mouse_events = true;\n","\n","    canvas_div.resizable({\n","        start: function(event, ui) {\n","            pass_mouse_events = false;\n","        },\n","        resize: function(event, ui) {\n","            fig.request_resize(ui.size.width, ui.size.height);\n","        },\n","        stop: function(event, ui) {\n","            pass_mouse_events = true;\n","            fig.request_resize(ui.size.width, ui.size.height);\n","        },\n","    });\n","\n","    function mouse_event_fn(event) {\n","        if (pass_mouse_events)\n","            return fig.mouse_event(event, event['data']);\n","    }\n","\n","    rubberband.mousedown('button_press', mouse_event_fn);\n","    rubberband.mouseup('button_release', mouse_event_fn);\n","    // Throttle sequential mouse events to 1 every 20ms.\n","    rubberband.mousemove('motion_notify', mouse_event_fn);\n","\n","    rubberband.mouseenter('figure_enter', mouse_event_fn);\n","    rubberband.mouseleave('figure_leave', mouse_event_fn);\n","\n","    canvas_div.on(\"wheel\", function (event) {\n","        event = event.originalEvent;\n","        event['data'] = 'scroll'\n","        if (event.deltaY < 0) {\n","            event.step = 1;\n","        } else {\n","            event.step = -1;\n","        }\n","        mouse_event_fn(event);\n","    });\n","\n","    canvas_div.append(canvas);\n","    canvas_div.append(rubberband);\n","\n","    this.rubberband = rubberband;\n","    this.rubberband_canvas = rubberband[0];\n","    this.rubberband_context = rubberband[0].getContext(\"2d\");\n","    this.rubberband_context.strokeStyle = \"#000000\";\n","\n","    this._resize_canvas = function(width, height) {\n","        // Keep the size of the canvas, canvas container, and rubber band\n","        // canvas in synch.\n","        canvas_div.css('width', width)\n","        canvas_div.css('height', height)\n","\n","        canvas.attr('width', width * mpl.ratio);\n","        canvas.attr('height', height * mpl.ratio);\n","        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n","\n","        rubberband.attr('width', width);\n","        rubberband.attr('height', height);\n","    }\n","\n","    // Set the figure to an initial 600x600px, this will subsequently be updated\n","    // upon first draw.\n","    this._resize_canvas(600, 600);\n","\n","    // Disable right mouse context menu.\n","    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n","        return false;\n","    });\n","\n","    function set_focus () {\n","        canvas.focus();\n","        canvas_div.focus();\n","    }\n","\n","    window.setTimeout(set_focus, 100);\n","}\n","\n","mpl.figure.prototype._init_toolbar = function() {\n","    var fig = this;\n","\n","    var nav_element = $('<div/>');\n","    nav_element.attr('style', 'width: 100%');\n","    this.root.append(nav_element);\n","\n","    // Define a callback function for later on.\n","    function toolbar_event(event) {\n","        return fig.toolbar_button_onclick(event['data']);\n","    }\n","    function toolbar_mouse_event(event) {\n","        return fig.toolbar_button_onmouseover(event['data']);\n","    }\n","\n","    for(var toolbar_ind in mpl.toolbar_items) {\n","        var name = mpl.toolbar_items[toolbar_ind][0];\n","        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n","        var image = mpl.toolbar_items[toolbar_ind][2];\n","        var method_name = mpl.toolbar_items[toolbar_ind][3];\n","\n","        if (!name) {\n","            // put a spacer in here.\n","            continue;\n","        }\n","        var button = $('<button/>');\n","        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n","                        'ui-button-icon-only');\n","        button.attr('role', 'button');\n","        button.attr('aria-disabled', 'false');\n","        button.click(method_name, toolbar_event);\n","        button.mouseover(tooltip, toolbar_mouse_event);\n","\n","        var icon_img = $('<span/>');\n","        icon_img.addClass('ui-button-icon-primary ui-icon');\n","        icon_img.addClass(image);\n","        icon_img.addClass('ui-corner-all');\n","\n","        var tooltip_span = $('<span/>');\n","        tooltip_span.addClass('ui-button-text');\n","        tooltip_span.html(tooltip);\n","\n","        button.append(icon_img);\n","        button.append(tooltip_span);\n","\n","        nav_element.append(button);\n","    }\n","\n","    var fmt_picker_span = $('<span/>');\n","\n","    var fmt_picker = $('<select/>');\n","    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n","    fmt_picker_span.append(fmt_picker);\n","    nav_element.append(fmt_picker_span);\n","    this.format_dropdown = fmt_picker[0];\n","\n","    for (var ind in mpl.extensions) {\n","        var fmt = mpl.extensions[ind];\n","        var option = $(\n","            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n","        fmt_picker.append(option);\n","    }\n","\n","    // Add hover states to the ui-buttons\n","    $( \".ui-button\" ).hover(\n","        function() { $(this).addClass(\"ui-state-hover\");},\n","        function() { $(this).removeClass(\"ui-state-hover\");}\n","    );\n","\n","    var status_bar = $('<span class=\"mpl-message\"/>');\n","    nav_element.append(status_bar);\n","    this.message = status_bar[0];\n","}\n","\n","mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n","    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n","    // which will in turn request a refresh of the image.\n","    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n","}\n","\n","mpl.figure.prototype.send_message = function(type, properties) {\n","    properties['type'] = type;\n","    properties['figure_id'] = this.id;\n","    this.ws.send(JSON.stringify(properties));\n","}\n","\n","mpl.figure.prototype.send_draw_message = function() {\n","    if (!this.waiting) {\n","        this.waiting = true;\n","        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n","    }\n","}\n","\n","\n","mpl.figure.prototype.handle_save = function(fig, msg) {\n","    var format_dropdown = fig.format_dropdown;\n","    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n","    fig.ondownload(fig, format);\n","}\n","\n","\n","mpl.figure.prototype.handle_resize = function(fig, msg) {\n","    var size = msg['size'];\n","    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n","        fig._resize_canvas(size[0], size[1]);\n","        fig.send_message(\"refresh\", {});\n","    };\n","}\n","\n","mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n","    var x0 = msg['x0'] / mpl.ratio;\n","    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n","    var x1 = msg['x1'] / mpl.ratio;\n","    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n","    x0 = Math.floor(x0) + 0.5;\n","    y0 = Math.floor(y0) + 0.5;\n","    x1 = Math.floor(x1) + 0.5;\n","    y1 = Math.floor(y1) + 0.5;\n","    var min_x = Math.min(x0, x1);\n","    var min_y = Math.min(y0, y1);\n","    var width = Math.abs(x1 - x0);\n","    var height = Math.abs(y1 - y0);\n","\n","    fig.rubberband_context.clearRect(\n","        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n","\n","    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n","}\n","\n","mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n","    // Updates the figure title.\n","    fig.header.textContent = msg['label'];\n","}\n","\n","mpl.figure.prototype.handle_cursor = function(fig, msg) {\n","    var cursor = msg['cursor'];\n","    switch(cursor)\n","    {\n","    case 0:\n","        cursor = 'pointer';\n","        break;\n","    case 1:\n","        cursor = 'default';\n","        break;\n","    case 2:\n","        cursor = 'crosshair';\n","        break;\n","    case 3:\n","        cursor = 'move';\n","        break;\n","    }\n","    fig.rubberband_canvas.style.cursor = cursor;\n","}\n","\n","mpl.figure.prototype.handle_message = function(fig, msg) {\n","    fig.message.textContent = msg['message'];\n","}\n","\n","mpl.figure.prototype.handle_draw = function(fig, msg) {\n","    // Request the server to send over a new figure.\n","    fig.send_draw_message();\n","}\n","\n","mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n","    fig.image_mode = msg['mode'];\n","}\n","\n","mpl.figure.prototype.updated_canvas_event = function() {\n","    // Called whenever the canvas gets updated.\n","    this.send_message(\"ack\", {});\n","}\n","\n","// A function to construct a web socket function for onmessage handling.\n","// Called in the figure constructor.\n","mpl.figure.prototype._make_on_message_function = function(fig) {\n","    return function socket_on_message(evt) {\n","        if (evt.data instanceof Blob) {\n","            /* FIXME: We get \"Resource interpreted as Image but\n","             * transferred with MIME type text/plain:\" errors on\n","             * Chrome.  But how to set the MIME type?  It doesn't seem\n","             * to be part of the websocket stream */\n","            evt.data.type = \"image/png\";\n","\n","            /* Free the memory for the previous frames */\n","            if (fig.imageObj.src) {\n","                (window.URL || window.webkitURL).revokeObjectURL(\n","                    fig.imageObj.src);\n","            }\n","\n","            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n","                evt.data);\n","            fig.updated_canvas_event();\n","            fig.waiting = false;\n","            return;\n","        }\n","        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n","            fig.imageObj.src = evt.data;\n","            fig.updated_canvas_event();\n","            fig.waiting = false;\n","            return;\n","        }\n","\n","        var msg = JSON.parse(evt.data);\n","        var msg_type = msg['type'];\n","\n","        // Call the  \"handle_{type}\" callback, which takes\n","        // the figure and JSON message as its only arguments.\n","        try {\n","            var callback = fig[\"handle_\" + msg_type];\n","        } catch (e) {\n","            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n","            return;\n","        }\n","\n","        if (callback) {\n","            try {\n","                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n","                callback(fig, msg);\n","            } catch (e) {\n","                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n","            }\n","        }\n","    };\n","}\n","\n","// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n","mpl.findpos = function(e) {\n","    //this section is from http://www.quirksmode.org/js/events_properties.html\n","    var targ;\n","    if (!e)\n","        e = window.event;\n","    if (e.target)\n","        targ = e.target;\n","    else if (e.srcElement)\n","        targ = e.srcElement;\n","    if (targ.nodeType == 3) // defeat Safari bug\n","        targ = targ.parentNode;\n","\n","    // jQuery normalizes the pageX and pageY\n","    // pageX,Y are the mouse positions relative to the document\n","    // offset() returns the position of the element relative to the document\n","    var x = e.pageX - $(targ).offset().left;\n","    var y = e.pageY - $(targ).offset().top;\n","\n","    return {\"x\": x, \"y\": y};\n","};\n","\n","/*\n"," * return a copy of an object with only non-object keys\n"," * we need this to avoid circular references\n"," * http://stackoverflow.com/a/24161582/3208463\n"," */\n","function simpleKeys (original) {\n","  return Object.keys(original).reduce(function (obj, key) {\n","    if (typeof original[key] !== 'object')\n","        obj[key] = original[key]\n","    return obj;\n","  }, {});\n","}\n","\n","mpl.figure.prototype.mouse_event = function(event, name) {\n","    var canvas_pos = mpl.findpos(event)\n","\n","    if (name === 'button_press')\n","    {\n","        this.canvas.focus();\n","        this.canvas_div.focus();\n","    }\n","\n","    var x = canvas_pos.x * mpl.ratio;\n","    var y = canvas_pos.y * mpl.ratio;\n","\n","    this.send_message(name, {x: x, y: y, button: event.button,\n","                             step: event.step,\n","                             guiEvent: simpleKeys(event)});\n","\n","    /* This prevents the web browser from automatically changing to\n","     * the text insertion cursor when the button is pressed.  We want\n","     * to control all of the cursor setting manually through the\n","     * 'cursor' event from matplotlib */\n","    event.preventDefault();\n","    return false;\n","}\n","\n","mpl.figure.prototype._key_event_extra = function(event, name) {\n","    // Handle any extra behaviour associated with a key event\n","}\n","\n","mpl.figure.prototype.key_event = function(event, name) {\n","\n","    // Prevent repeat events\n","    if (name == 'key_press')\n","    {\n","        if (event.which === this._key)\n","            return;\n","        else\n","            this._key = event.which;\n","    }\n","    if (name == 'key_release')\n","        this._key = null;\n","\n","    var value = '';\n","    if (event.ctrlKey && event.which != 17)\n","        value += \"ctrl+\";\n","    if (event.altKey && event.which != 18)\n","        value += \"alt+\";\n","    if (event.shiftKey && event.which != 16)\n","        value += \"shift+\";\n","\n","    value += 'k';\n","    value += event.which.toString();\n","\n","    this._key_event_extra(event, name);\n","\n","    this.send_message(name, {key: value,\n","                             guiEvent: simpleKeys(event)});\n","    return false;\n","}\n","\n","mpl.figure.prototype.toolbar_button_onclick = function(name) {\n","    if (name == 'download') {\n","        this.handle_save(this, null);\n","    } else {\n","        this.send_message(\"toolbar_button\", {name: name});\n","    }\n","};\n","\n","mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n","    this.message.textContent = tooltip;\n","};\n","mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n","\n","mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n","\n","mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n","    // Create a \"websocket\"-like object which calls the given IPython comm\n","    // object with the appropriate methods. Currently this is a non binary\n","    // socket, so there is still some room for performance tuning.\n","    var ws = {};\n","\n","    ws.close = function() {\n","        comm.close()\n","    };\n","    ws.send = function(m) {\n","        //console.log('sending', m);\n","        comm.send(m);\n","    };\n","    // Register the callback with on_msg.\n","    comm.on_msg(function(msg) {\n","        //console.log('receiving', msg['content']['data'], msg);\n","        // Pass the mpl event to the overridden (by mpl) onmessage function.\n","        ws.onmessage(msg['content']['data'])\n","    });\n","    return ws;\n","}\n","\n","mpl.mpl_figure_comm = function(comm, msg) {\n","    // This is the function which gets called when the mpl process\n","    // starts-up an IPython Comm through the \"matplotlib\" channel.\n","\n","    var id = msg.content.data.id;\n","    // Get hold of the div created by the display call when the Comm\n","    // socket was opened in Python.\n","    var element = $(\"#\" + id);\n","    var ws_proxy = comm_websocket_adapter(comm)\n","\n","    function ondownload(figure, format) {\n","        window.open(figure.imageObj.src);\n","    }\n","\n","    var fig = new mpl.figure(id, ws_proxy,\n","                           ondownload,\n","                           element.get(0));\n","\n","    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n","    // web socket which is closed, not our websocket->open comm proxy.\n","    ws_proxy.onopen();\n","\n","    fig.parent_element = element.get(0);\n","    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n","    if (!fig.cell_info) {\n","        console.error(\"Failed to find cell for figure\", id, fig);\n","        return;\n","    }\n","\n","    var output_index = fig.cell_info[2]\n","    var cell = fig.cell_info[0];\n","\n","};\n","\n","mpl.figure.prototype.handle_close = function(fig, msg) {\n","    var width = fig.canvas.width/mpl.ratio\n","    fig.root.unbind('remove')\n","\n","    // Update the output cell to use the data from the current canvas.\n","    fig.push_to_output();\n","    var dataURL = fig.canvas.toDataURL();\n","    // Re-enable the keyboard manager in IPython - without this line, in FF,\n","    // the notebook keyboard shortcuts fail.\n","    IPython.keyboard_manager.enable()\n","    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n","    fig.close_ws(fig, msg);\n","}\n","\n","mpl.figure.prototype.close_ws = function(fig, msg){\n","    fig.send_message('closing', msg);\n","    // fig.ws.close()\n","}\n","\n","mpl.figure.prototype.push_to_output = function(remove_interactive) {\n","    // Turn the data on the canvas into data in the output cell.\n","    var width = this.canvas.width/mpl.ratio\n","    var dataURL = this.canvas.toDataURL();\n","    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n","}\n","\n","mpl.figure.prototype.updated_canvas_event = function() {\n","    // Tell IPython that the notebook contents must change.\n","    IPython.notebook.set_dirty(true);\n","    this.send_message(\"ack\", {});\n","    var fig = this;\n","    // Wait a second, then push the new image to the DOM so\n","    // that it is saved nicely (might be nice to debounce this).\n","    setTimeout(function () { fig.push_to_output() }, 1000);\n","}\n","\n","mpl.figure.prototype._init_toolbar = function() {\n","    var fig = this;\n","\n","    var nav_element = $('<div/>');\n","    nav_element.attr('style', 'width: 100%');\n","    this.root.append(nav_element);\n","\n","    // Define a callback function for later on.\n","    function toolbar_event(event) {\n","        return fig.toolbar_button_onclick(event['data']);\n","    }\n","    function toolbar_mouse_event(event) {\n","        return fig.toolbar_button_onmouseover(event['data']);\n","    }\n","\n","    for(var toolbar_ind in mpl.toolbar_items){\n","        var name = mpl.toolbar_items[toolbar_ind][0];\n","        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n","        var image = mpl.toolbar_items[toolbar_ind][2];\n","        var method_name = mpl.toolbar_items[toolbar_ind][3];\n","\n","        if (!name) { continue; };\n","\n","        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n","        button.click(method_name, toolbar_event);\n","        button.mouseover(tooltip, toolbar_mouse_event);\n","        nav_element.append(button);\n","    }\n","\n","    // Add the status bar.\n","    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n","    nav_element.append(status_bar);\n","    this.message = status_bar[0];\n","\n","    // Add the close button to the window.\n","    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n","    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n","    button.click(function (evt) { fig.handle_close(fig, {}); } );\n","    button.mouseover('Stop Interaction', toolbar_mouse_event);\n","    buttongrp.append(button);\n","    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n","    titlebar.prepend(buttongrp);\n","}\n","\n","mpl.figure.prototype._root_extra_style = function(el){\n","    var fig = this\n","    el.on(\"remove\", function(){\n","\tfig.close_ws(fig, {});\n","    });\n","}\n","\n","mpl.figure.prototype._canvas_extra_style = function(el){\n","    // this is important to make the div 'focusable\n","    el.attr('tabindex', 0)\n","    // reach out to IPython and tell the keyboard manager to turn it's self\n","    // off when our div gets focus\n","\n","    // location in version 3\n","    if (IPython.notebook.keyboard_manager) {\n","        IPython.notebook.keyboard_manager.register_events(el);\n","    }\n","    else {\n","        // location in version 2\n","        IPython.keyboard_manager.register_events(el);\n","    }\n","\n","}\n","\n","mpl.figure.prototype._key_event_extra = function(event, name) {\n","    var manager = IPython.notebook.keyboard_manager;\n","    if (!manager)\n","        manager = IPython.keyboard_manager;\n","\n","    // Check for shift+enter\n","    if (event.shiftKey && event.which == 13) {\n","        this.canvas_div.blur();\n","        // select the cell after this one\n","        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n","        IPython.notebook.select(index + 1);\n","    }\n","}\n","\n","mpl.figure.prototype.handle_save = function(fig, msg) {\n","    fig.ondownload(fig, null);\n","}\n","\n","\n","mpl.find_output_cell = function(html_output) {\n","    // Return the cell and output element which can be found *uniquely* in the notebook.\n","    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n","    // IPython event is triggered only after the cells have been serialised, which for\n","    // our purposes (turning an active figure into a static one), is too late.\n","    var cells = IPython.notebook.get_cells();\n","    var ncells = cells.length;\n","    for (var i=0; i<ncells; i++) {\n","        var cell = cells[i];\n","        if (cell.cell_type === 'code'){\n","            for (var j=0; j<cell.output_area.outputs.length; j++) {\n","                var data = cell.output_area.outputs[j];\n","                if (data.data) {\n","                    // IPython >= 3 moved mimebundle to data attribute of output\n","                    data = data.data;\n","                }\n","                if (data['text/html'] == html_output) {\n","                    return [cell, data, j];\n","                }\n","            }\n","        }\n","    }\n","}\n","\n","// Register the function which deals with the matplotlib target/channel.\n","// The kernel may be null if the page has been refreshed.\n","if (IPython.notebook.kernel != null) {\n","    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n","}\n"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<div id='6588fa37-24cb-46ba-ac07-06ac3e6ee993'></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"z4TyyT2NT58Z","colab_type":"text"},"source":["### **MLP network with one layer hidden in the CIFAR-10 problem**"]},{"cell_type":"code","metadata":{"id":"Qz2gfwpiUFZC","colab_type":"code","outputId":"b7eeef1c-419d-40be-d807-bdbe0857e007","executionInfo":{"status":"ok","timestamp":1580294111426,"user_tz":-60,"elapsed":36448,"user":{"displayName":"Miguel Fernández","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_ckDCkb0V8ABako_2n9-az8dxyRyTbDJTpzjTKcg=s64","userId":"00918429620522674110"}},"colab":{"base_uri":"https://localhost:8080/","height":935}},"source":["import tensorflow as tf\n","import numpy\n","import keras\n","from keras.datasets import cifar10\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.models import load_model\n","from keras.utils import np_utils\n","\n","#If necessary, change the current catalog\n","#import os\n","#path = '.'\n","#os.chdir(path)\n","\n","print(tf.__version__)\n","print(keras.__version__)\n","\n","(xtrain, ytrain), (xtest, ytest) = cifar10.load_data()\n","print('xtrain.shape',xtrain.shape)\n","print('ytrain.shape',ytrain.shape)\n","print('xtest.shape',xtest.shape)\n","print('ytest.shape',ytest.shape)\n","\n","seed = 12345\n","numpy.random.seed(seed)\n","\n","inputs_num = xtrain.shape[1] * xtrain.shape[2] * xtrain.shape[3] #number of pixels = number of network inputs\n","xtrain = xtrain.reshape(xtrain.shape[0], inputs_num).astype('float32')\n","xtest = xtest.reshape(xtest.shape[0], inputs_num).astype('float32')\n","\n","# normalize inputs from 0-255 to 0-1\n","xtrain = xtrain / 255\n","xtest = xtest / 255\n","\n","print(xtrain.shape)\n","print(xtest.shape)\n","\n","ytrain = np_utils.to_categorical(ytrain)\n","ytest = np_utils.to_categorical(ytest)\n","num_classes = ytest.shape[1]\n","print(ytest.shape)\n","\n","model = Sequential()\n","model.add(Dense(500, input_dim=inputs_num, kernel_initializer='normal', activation='relu'))\n","model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","logger = keras.callbacks.ModelCheckpoint('cifar10_model_MLP.hdf5', monitor='val_acc', verbose=0, save_best_only=True)\n","\n","model.fit(xtrain, ytrain, validation_data=(xtest, ytest), epochs=20, batch_size=200, verbose=2, callbacks=[logger])\n","\n","scores = model.evaluate(xtest, ytest, verbose=0)\n","print(\"Test error: %.2f%%\" % (100-scores[1]*100))\n","\n","#reading the best model from file\n","model2 = load_model('cifar10_model_MLP.hdf5')\n","scores2 = model2.evaluate(xtest, ytest, batch_size=200)\n","print('network from file:')\n","print(\"Test error: %.2f%%\" % (100-scores2[1]*100))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.15.0\n","2.2.5\n","xtrain.shape (50000, 32, 32, 3)\n","ytrain.shape (50000, 1)\n","xtest.shape (10000, 32, 32, 3)\n","ytest.shape (10000, 1)\n","(50000, 3072)\n","(10000, 3072)\n","(10000, 10)\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/20\n"," - 2s - loss: 1.9138 - acc: 0.3307 - val_loss: 1.7884 - val_acc: 0.3607\n","Epoch 2/20\n"," - 2s - loss: 1.6905 - acc: 0.4029 - val_loss: 1.6439 - val_acc: 0.4093\n","Epoch 3/20\n"," - 2s - loss: 1.6220 - acc: 0.4290 - val_loss: 1.6145 - val_acc: 0.4197\n","Epoch 4/20\n"," - 2s - loss: 1.5745 - acc: 0.4462 - val_loss: 1.5741 - val_acc: 0.4360\n","Epoch 5/20\n"," - 2s - loss: 1.5303 - acc: 0.4595 - val_loss: 1.5159 - val_acc: 0.4633\n","Epoch 6/20\n"," - 1s - loss: 1.4898 - acc: 0.4736 - val_loss: 1.5189 - val_acc: 0.4551\n","Epoch 7/20\n"," - 2s - loss: 1.4707 - acc: 0.4800 - val_loss: 1.4809 - val_acc: 0.4745\n","Epoch 8/20\n"," - 2s - loss: 1.4438 - acc: 0.4919 - val_loss: 1.4757 - val_acc: 0.4767\n","Epoch 9/20\n"," - 2s - loss: 1.4221 - acc: 0.4993 - val_loss: 1.4596 - val_acc: 0.4797\n","Epoch 10/20\n"," - 1s - loss: 1.3995 - acc: 0.5057 - val_loss: 1.4375 - val_acc: 0.4989\n","Epoch 11/20\n"," - 2s - loss: 1.3851 - acc: 0.5122 - val_loss: 1.4301 - val_acc: 0.4972\n","Epoch 12/20\n"," - 2s - loss: 1.3666 - acc: 0.5165 - val_loss: 1.4408 - val_acc: 0.4906\n","Epoch 13/20\n"," - 1s - loss: 1.3513 - acc: 0.5241 - val_loss: 1.4604 - val_acc: 0.4887\n","Epoch 14/20\n"," - 1s - loss: 1.3381 - acc: 0.5275 - val_loss: 1.4449 - val_acc: 0.4906\n","Epoch 15/20\n"," - 2s - loss: 1.3325 - acc: 0.5310 - val_loss: 1.4601 - val_acc: 0.4911\n","Epoch 16/20\n"," - 2s - loss: 1.3106 - acc: 0.5396 - val_loss: 1.4455 - val_acc: 0.4919\n","Epoch 17/20\n"," - 2s - loss: 1.3011 - acc: 0.5419 - val_loss: 1.4127 - val_acc: 0.5020\n","Epoch 18/20\n"," - 1s - loss: 1.2875 - acc: 0.5446 - val_loss: 1.4602 - val_acc: 0.4899\n","Epoch 19/20\n"," - 1s - loss: 1.2714 - acc: 0.5509 - val_loss: 1.4078 - val_acc: 0.5061\n","Epoch 20/20\n"," - 1s - loss: 1.2600 - acc: 0.5574 - val_loss: 1.3904 - val_acc: 0.5145\n","Test error: 48.55%\n","10000/10000 [==============================] - 0s 40us/step\n","network from file:\n","Test error: 48.55%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zsQ2_RVbVFUH","colab_type":"text"},"source":["### **Simple CNN in the CIFAR-10 problem**"]},{"cell_type":"code","metadata":{"id":"B1JI208JVFsZ","colab_type":"code","outputId":"0c56c813-12ff-421f-ef68-588e1da92d78","executionInfo":{"status":"ok","timestamp":1580294251787,"user_tz":-60,"elapsed":57550,"user":{"displayName":"Miguel Fernández","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_ckDCkb0V8ABako_2n9-az8dxyRyTbDJTpzjTKcg=s64","userId":"00918429620522674110"}},"colab":{"base_uri":"https://localhost:8080/","height":884}},"source":["import tensorflow as tf\n","import numpy as np\n","import keras\n","from keras.datasets import cifar10\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import Flatten\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.models import load_model\n","from keras.utils import np_utils\n","\n","#import os\n","#path = '.'\n","#os.chdir(path)\n","\n","print(tf.__version__)\n","print(keras.__version__)\n","\n","(xtrain, ytrain), (xtest, ytest) = cifar10.load_data()\n","print('xtrain.shape',xtrain.shape)\n","print('ytrain.shape',ytrain.shape)\n","print('xtest.shape',xtest.shape)\n","print('ytest.shape',ytest.shape)\n","\n","seed = 12345\n","np.random.seed(seed)\n","\n","xtrain = xtrain.reshape(xtrain.shape[0], 32, 32, 3).astype('float32')\n","xtest = xtest.reshape(xtest.shape[0], 32, 32, 3).astype('float32')\n","\n","# normalize inputs from 0-255 to 0-1\n","xtrain = xtrain / 255\n","xtest = xtest / 255\n","\n","# one hot encode outputs\n","ytrain = np_utils.to_categorical(ytrain)\n","ytest = np_utils.to_categorical(ytest)\n","num_classes = ytest.shape[1]\n","\n","model = Sequential()\n","model.add(Conv2D(32, (5, 5), input_shape=(32, 32, 3), activation='relu', data_format='channels_last'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.2))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","logger = keras.callbacks.ModelCheckpoint('cifar10_model_CONV_SIMPLE.hdf5', monitor='val_acc', verbose=0, save_best_only=True)\n","\n","# Fit the model\n","model.fit(xtrain, ytrain, validation_data=(xtest, ytest), epochs=20, batch_size=200, verbose=2, callbacks=[logger])\n","\n","scores = model.evaluate(xtest, ytest, verbose=0)\n","print(\"Test error: %.2f%%\" % (100-scores[1]*100))\n","\n","#Best model\n","model2 = load_model('cifar10_model_CONV_SIMPLE.hdf5')\n","scores2 = model2.evaluate(xtest, ytest, batch_size=200)\n","print('The best network from file:')\n","print(\"Test error: %.2f%%\" % (100-scores2[1]*100))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.15.0\n","2.2.5\n","xtrain.shape (50000, 32, 32, 3)\n","ytrain.shape (50000, 1)\n","xtest.shape (10000, 32, 32, 3)\n","ytest.shape (10000, 1)\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/20\n"," - 4s - loss: 1.6285 - acc: 0.4218 - val_loss: 1.3700 - val_acc: 0.5143\n","Epoch 2/20\n"," - 2s - loss: 1.2834 - acc: 0.5492 - val_loss: 1.2258 - val_acc: 0.5629\n","Epoch 3/20\n"," - 2s - loss: 1.1647 - acc: 0.5918 - val_loss: 1.1481 - val_acc: 0.5995\n","Epoch 4/20\n"," - 3s - loss: 1.0884 - acc: 0.6216 - val_loss: 1.1075 - val_acc: 0.6129\n","Epoch 5/20\n"," - 2s - loss: 1.0262 - acc: 0.6407 - val_loss: 1.0636 - val_acc: 0.6300\n","Epoch 6/20\n"," - 2s - loss: 0.9899 - acc: 0.6550 - val_loss: 1.0420 - val_acc: 0.6349\n","Epoch 7/20\n"," - 2s - loss: 0.9387 - acc: 0.6735 - val_loss: 1.0135 - val_acc: 0.6480\n","Epoch 8/20\n"," - 2s - loss: 0.9042 - acc: 0.6870 - val_loss: 1.0166 - val_acc: 0.6456\n","Epoch 9/20\n"," - 3s - loss: 0.8634 - acc: 0.7007 - val_loss: 0.9932 - val_acc: 0.6600\n","Epoch 10/20\n"," - 2s - loss: 0.8408 - acc: 0.7068 - val_loss: 0.9917 - val_acc: 0.6563\n","Epoch 11/20\n"," - 3s - loss: 0.8116 - acc: 0.7193 - val_loss: 0.9862 - val_acc: 0.6599\n","Epoch 12/20\n"," - 2s - loss: 0.7703 - acc: 0.7333 - val_loss: 0.9797 - val_acc: 0.6632\n","Epoch 13/20\n"," - 3s - loss: 0.7505 - acc: 0.7387 - val_loss: 0.9995 - val_acc: 0.6571\n","Epoch 14/20\n"," - 2s - loss: 0.7155 - acc: 0.7508 - val_loss: 0.9950 - val_acc: 0.6626\n","Epoch 15/20\n"," - 2s - loss: 0.7033 - acc: 0.7537 - val_loss: 1.0242 - val_acc: 0.6555\n","Epoch 16/20\n"," - 2s - loss: 0.6735 - acc: 0.7654 - val_loss: 0.9811 - val_acc: 0.6643\n","Epoch 17/20\n"," - 3s - loss: 0.6481 - acc: 0.7730 - val_loss: 1.0074 - val_acc: 0.6627\n","Epoch 18/20\n"," - 2s - loss: 0.6288 - acc: 0.7800 - val_loss: 1.0314 - val_acc: 0.6655\n","Epoch 19/20\n"," - 2s - loss: 0.6052 - acc: 0.7884 - val_loss: 1.0044 - val_acc: 0.6681\n","Epoch 20/20\n"," - 2s - loss: 0.5853 - acc: 0.7955 - val_loss: 1.0173 - val_acc: 0.6732\n","Test error: 32.68%\n","10000/10000 [==============================] - 1s 60us/step\n","The best network from file:\n","Test error: 32.68%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2DVLAa7AVGgB","colab_type":"text"},"source":["### **Bigger CNN in the CIFAR-10 problem**"]},{"cell_type":"code","metadata":{"id":"4WfdLqykVG1k","colab_type":"code","outputId":"965ad9d2-b40b-4d2c-bccd-079a123a68ab","executionInfo":{"status":"ok","timestamp":1580294339048,"user_tz":-60,"elapsed":59231,"user":{"displayName":"Miguel Fernández","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_ckDCkb0V8ABako_2n9-az8dxyRyTbDJTpzjTKcg=s64","userId":"00918429620522674110"}},"colab":{"base_uri":"https://localhost:8080/","height":901}},"source":["import tensorflow as tf\n","import numpy as np\n","import keras\n","from keras.datasets import cifar10\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import Flatten\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.models import load_model\n","from keras.utils import np_utils\n","\n","#import os\n","#path = '.'\n","#os.chdir(path)\n","\n","print(tf.__version__)\n","print(keras.__version__)\n","\n","(xtrain, ytrain), (xtest, ytest) = cifar10.load_data()\n","print('xtrain.shape',xtrain.shape)\n","print('ytrain.shape',ytrain.shape)\n","print('xtest.shape',xtest.shape)\n","print('ytest.shape',ytest.shape)\n","\n","# fix random seed\n","seed = 12345\n","np.random.seed(seed)\n","\n","\n","xtrain = xtrain.reshape(xtrain.shape[0], 32, 32, 3).astype('float32')\n","xtest = xtest.reshape(xtest.shape[0], 32, 32, 3).astype('float32')\n","\n","# normalize inputs from 0-255 to 0-1\n","xtrain = xtrain / 255\n","xtest = xtest / 255\n","\n","# one hot encode outputs\n","ytrain = np_utils.to_categorical(ytrain)\n","ytest = np_utils.to_categorical(ytest)\n","num_classes = ytest.shape[1]\n","\n","# define model\n","model = Sequential()\n","model.add(Conv2D(30, (5, 5), input_shape=(32, 32, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(15, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.2))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(50, activation='relu'))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","logger = keras.callbacks.ModelCheckpoint('cifar10_model_CONV_BIGGER.hdf5', monitor='val_acc', verbose=0, save_best_only=True)\n","\n","# Fit the model\n","model.fit(xtrain, ytrain, validation_data=(xtest, ytest), epochs=20, batch_size=200, verbose=2, callbacks=[logger])\n","\n","# Final evaluation of the model\n","scores = model.evaluate(xtest, ytest, verbose=0)\n","print(\"Test error: %.2f%%\" % (100-scores[1]*100))\n","\n","#Best model\n","model2 = load_model('cifar10_model_CONV_BIGGER.hdf5')\n","scores2 = model2.evaluate(xtest, ytest, batch_size=200)\n","print('The best network from the file:')\n","print(\"Test error: %.2f%%\" % (100-scores2[1]*100))\n","\n","print('end')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.15.0\n","2.2.5\n","xtrain.shape (50000, 32, 32, 3)\n","ytrain.shape (50000, 1)\n","xtest.shape (10000, 32, 32, 3)\n","ytest.shape (10000, 1)\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/20\n"," - 4s - loss: 1.7604 - acc: 0.3539 - val_loss: 1.4921 - val_acc: 0.4536\n","Epoch 2/20\n"," - 3s - loss: 1.4500 - acc: 0.4720 - val_loss: 1.3755 - val_acc: 0.5070\n","Epoch 3/20\n"," - 3s - loss: 1.3407 - acc: 0.5138 - val_loss: 1.2641 - val_acc: 0.5451\n","Epoch 4/20\n"," - 2s - loss: 1.2554 - acc: 0.5517 - val_loss: 1.1919 - val_acc: 0.5727\n","Epoch 5/20\n"," - 3s - loss: 1.2007 - acc: 0.5706 - val_loss: 1.1702 - val_acc: 0.5853\n","Epoch 6/20\n"," - 3s - loss: 1.1415 - acc: 0.5929 - val_loss: 1.1076 - val_acc: 0.6115\n","Epoch 7/20\n"," - 3s - loss: 1.0953 - acc: 0.6112 - val_loss: 1.0822 - val_acc: 0.6143\n","Epoch 8/20\n"," - 3s - loss: 1.0622 - acc: 0.6257 - val_loss: 1.0316 - val_acc: 0.6357\n","Epoch 9/20\n"," - 2s - loss: 1.0274 - acc: 0.6359 - val_loss: 1.0229 - val_acc: 0.6400\n","Epoch 10/20\n"," - 2s - loss: 0.9953 - acc: 0.6457 - val_loss: 1.0141 - val_acc: 0.6398\n","Epoch 11/20\n"," - 2s - loss: 0.9728 - acc: 0.6545 - val_loss: 0.9901 - val_acc: 0.6508\n","Epoch 12/20\n"," - 2s - loss: 0.9446 - acc: 0.6682 - val_loss: 0.9524 - val_acc: 0.6656\n","Epoch 13/20\n"," - 2s - loss: 0.9105 - acc: 0.6788 - val_loss: 0.9417 - val_acc: 0.6707\n","Epoch 14/20\n"," - 2s - loss: 0.8890 - acc: 0.6852 - val_loss: 0.9540 - val_acc: 0.6665\n","Epoch 15/20\n"," - 2s - loss: 0.8718 - acc: 0.6923 - val_loss: 0.9299 - val_acc: 0.6736\n","Epoch 16/20\n"," - 2s - loss: 0.8542 - acc: 0.6983 - val_loss: 0.9294 - val_acc: 0.6783\n","Epoch 17/20\n"," - 2s - loss: 0.8317 - acc: 0.7070 - val_loss: 0.9214 - val_acc: 0.6762\n","Epoch 18/20\n"," - 2s - loss: 0.8207 - acc: 0.7117 - val_loss: 0.9124 - val_acc: 0.6834\n","Epoch 19/20\n"," - 3s - loss: 0.8017 - acc: 0.7177 - val_loss: 0.9066 - val_acc: 0.6819\n","Epoch 20/20\n"," - 2s - loss: 0.7898 - acc: 0.7202 - val_loss: 0.8783 - val_acc: 0.6930\n","Test error: 30.70%\n","10000/10000 [==============================] - 1s 65us/step\n","The best network from the file:\n","Test error: 30.70%\n","end\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vm9YygZVWBfn","colab_type":"text"},"source":["**Comparing the results**"]},{"cell_type":"code","metadata":{"id":"Hn7NjzUNWB6X","colab_type":"code","outputId":"b6ab1443-f25a-4611-8af0-398f2462bb2e","executionInfo":{"status":"ok","timestamp":1580294581826,"user_tz":-60,"elapsed":14670,"user":{"displayName":"Miguel Fernández","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_ckDCkb0V8ABako_2n9-az8dxyRyTbDJTpzjTKcg=s64","userId":"00918429620522674110"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["import tensorflow as tf\n","import numpy as np\n","import keras\n","from keras.datasets import cifar10\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import Flatten\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.models import load_model\n","from keras.utils import np_utils\n","\n","#import os\n","#path = '.'\n","#os.chdir(path)\n","\n","print(tf.__version__)\n","print(keras.__version__)\n","\n","(xtrain, ytrain), (xtest, ytest) = cifar10.load_data()\n","print('xtrain.shape',xtrain.shape)\n","print('ytrain.shape',ytrain.shape)\n","print('xtest.shape',xtest.shape)\n","print('ytest.shape',ytest.shape)\n","\n","inputs_num = xtrain.shape[1] * xtrain.shape[2] * xtrain.shape[3] #number of pixels = number of network inputs\n","xtrain = xtrain.reshape(xtrain.shape[0], inputs_num).astype('float32')\n","xtest = xtest.reshape(xtest.shape[0], inputs_num).astype('float32')\n","\n","# normalize inputs from 0-255 to 0-1\n","xtrain = xtrain / 255\n","xtest = xtest / 255\n","\n","# one hot encode outputs\n","ytrain = np_utils.to_categorical(ytrain)\n","ytest = np_utils.to_categorical(ytest)\n","\n","#Compare the networks\n","\n","#MLP\n","model = load_model('cifar10_model_MLP.hdf5')\n","scores = model.evaluate(xtest, ytest, batch_size=200)\n","print(\"Test error (Model MLP): %.2f%%\" % (100-scores[1]*100))\n","\n","\n","xtrain = xtrain.reshape(xtrain.shape[0], 32, 32, 3).astype('float32')\n","xtest = xtest.reshape(xtest.shape[0], 32, 32, 3).astype('float32')\n","\n","#Smaller conv net\n","model = load_model('cifar10_model_CONV_SIMPLE.hdf5')\n","scores = model.evaluate(xtest, ytest, batch_size=200)\n","print(\"Test error (Model CONV SIMPLE): %.2f%%\" % (100-scores[1]*100))\n","\n","#Bigger conv net\n","model = load_model('cifar10_model_CONV_BIGGER.hdf5')\n","scores = model.evaluate(xtest, ytest, batch_size=200)\n","print(\"Test error (Model CONV BIGGER): %.2f%%\" % (100-scores[1]*100))\n","\n","print('end')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.15.0\n","2.2.5\n","xtrain.shape (50000, 32, 32, 3)\n","ytrain.shape (50000, 1)\n","xtest.shape (10000, 32, 32, 3)\n","ytest.shape (10000, 1)\n","10000/10000 [==============================] - 1s 67us/step\n","Test error (Model MLP): 48.55%\n","10000/10000 [==============================] - 1s 76us/step\n","Test error (Model CONV SIMPLE): 32.68%\n","10000/10000 [==============================] - 1s 82us/step\n","Test error (Model CONV BIGGER): 30.70%\n","end\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Nz37LenxUcqW","colab_type":"text"},"source":["### Task 2\n","\n","NOT OBLIGATORY, DO IT ONLY IF YOU WANT!\n","\n","- Collect your own images from different categories and train different networks to recognize them.\n","\n","- Provide the best models saved in files together with a script to load and test them."]},{"cell_type":"markdown","metadata":{"id":"WFt3VyegUcqX","colab_type":"text"},"source":["#### YOUR DESCRIPTION AND COMMENTS"]},{"cell_type":"code","metadata":{"id":"a-fM8bizUcqY","colab_type":"code","colab":{}},"source":["#YOUR CODE HERE"],"execution_count":0,"outputs":[]}]}