{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erasmus Neural Networks\n",
    "http://michalbereta.pl/nn\n",
    "## Control tasks for Perceptron and Widrow-Hoff model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "Exacute the examples.\n",
    "\n",
    "Then, do the tasks and send back the notebook.\n",
    "\n",
    "Change the name of this notebook according to the schema: {YourSurname}\\_{YourFirstName}\\_{OriginalFileName}.\n",
    "\n",
    "Be sure to fill all places with \"YOUR ANSWER HERE\".\n",
    "\n",
    "When ready, send the notebook, with all the necessary files zipped, to the teacher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to do\n",
    "\n",
    "- Fill the methods of the following classes with your implementation.\n",
    "\n",
    "- Read the comments to properly implement methods.\n",
    "\n",
    "- Avoid loops when possible. Use numpy operations on matrices and vectors, instead.\n",
    "\n",
    "- Execute the test code.\n",
    "\n",
    "- Compare the results with the expected results given.\n",
    "\n",
    "- Do not change the testing code, just the implementation od classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Online version of Perceptron learning\n",
    "\n",
    "Expected test output:\n",
    "\n",
    "`\n",
    "Loading train data...\n",
    "Train data:\n",
    "Number of examples= 500\n",
    "Number of inputs= 10\n",
    "Initial number of errors= 225\n",
    "Training...\n",
    "End of training\n",
    "Errors for train data after training= 0\n",
    "Loading test data...\n",
    "Test data:\n",
    "Number of examples= 439\n",
    "Number of inputs= 10\n",
    "Calculating answers for test data...\n",
    "Saving classifications for test data...\n",
    "Checking test error...\n",
    "Test errors= 2  ->  0.004555808656036446 %\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data...\n",
      "Train data:\n",
      "Number of examples= 500\n",
      "Number of inputs= 10\n",
      "Initial number of errors= 198\n",
      "Training...\n",
      "End of training\n",
      "Errors for train data after training= 0\n",
      "Loading test data...\n",
      "Test data:\n",
      "Number of examples= 439\n",
      "Number of inputs= 10\n",
      "Calculating answers for test data...\n",
      "Saving classifications for test data...\n",
      "Checking test error...\n",
      "Test errors= 0  ->  0.0 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import random\n",
    "\n",
    "class PerceptronOnline:\n",
    "    \"\"\"\n",
    "    This is a perceptron which can process one example at a time.\n",
    "    Assumption: class label is given as {-1, 1}\n",
    "    \"\"\"\n",
    "    def __init__(self, num_of_inputs):\n",
    "        \"\"\"Perceptron constructor\"\"\"\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.input_num = num_of_inputs\n",
    "        self.InitWeights()\n",
    "        \n",
    "    def InitWeights(self):\n",
    "        \"\"\"Initializes weights to random values\"\"\"\n",
    "        self.w = -1 + 2*np.random.random_sample(self.input_num,)\n",
    "        self.b = random.random()\n",
    "        \n",
    "    def Forward(self, x): \n",
    "        \"\"\"Forward pass - calculate the output as {-1, 1} of the neuron for one example x\"\"\"\n",
    "        y = np.dot(x, self.w) + self.b\n",
    "        return 1 if y > 0 else -1\n",
    "    \n",
    "    def Update(self, x, d, eta):\n",
    "        \"\"\"Calculate the output for x (one example), compare with d and update the weights if necessary\"\"\"\n",
    "        u = self.Forward(x)\n",
    "        if u!=d:\n",
    "            self.w += eta*x*d\n",
    "            self.b += eta*1*d\n",
    "            \n",
    "    def Train(self, X, D, eta, epochs):\n",
    "        \"\"\"\n",
    "        Train for the maximum number of epochs or until the classification error is 0\n",
    "        X: matrix with examples, each examples as a row\n",
    "        D: vector of correct class labels for examples in rows of X\n",
    "        The update to the weights vector is done after processing each example\n",
    "        \"\"\"\n",
    "        while epochs>0 and self.errors!=0:\n",
    "            for i in range(len(X)):\n",
    "                self.Update(X[i], D[i], eta)\n",
    "            epochs -= 1\n",
    "            \n",
    "    def CalculateErrors(self, X, D):\n",
    "        \"\"\"Calculates the number of errors - missclassifications\"\"\"\n",
    "        solution = 0\n",
    "        self.errors = 0\n",
    "        for i in range(len(D)):\n",
    "            solution = self.Forward(X[i])\n",
    "            if solution!=D[i]:\n",
    "                self.errors += 1\n",
    "        return self.errors\n",
    "    \n",
    "##############################################################################\n",
    "#DO NOT CHANGE THE FOLLOWING CODE\n",
    "##############################################################################\n",
    "print('Loading train data...')\n",
    "train_data = np.loadtxt('train10D.csv')\n",
    "X = train_data[:,:-1]\n",
    "D = train_data[:,-1]\n",
    "num_of_inputs = X.shape[1]\n",
    "print('Train data:')\n",
    "print('Number of examples=',X.shape[0])\n",
    "print('Number of inputs=',num_of_inputs)\n",
    "\n",
    "perc = PerceptronOnline(num_of_inputs)\n",
    "perc.InitWeights()\n",
    "\n",
    "start_errors = perc.CalculateErrors(X,D)\n",
    "print('Initial number of errors=',start_errors)\n",
    "\n",
    "print('Training...')\n",
    "max_epochs = 100\n",
    "eta = 0.01\n",
    "perc.Train(X, D, eta, max_epochs)\n",
    "print('End of training')\n",
    "\n",
    "train_errors = perc.CalculateErrors(X,D)\n",
    "print('Errors for train data after training=',train_errors)\n",
    "\n",
    "print('Loading test data...')\n",
    "test_data = np.loadtxt('test10D.csv')\n",
    "print('Test data:')\n",
    "print('Number of examples=',test_data.shape[0])\n",
    "print('Number of inputs=',test_data.shape[1])\n",
    "\n",
    "print('Calculating answers for test data...')\n",
    "test_ans = []\n",
    "for x in test_data:\n",
    "    test_ans.append ( perc.Forward(x) )\n",
    "test_ans = np.array(test_ans)\n",
    "print('Saving classifications for test data...')\n",
    "np.savetxt('test_data_classifications_perconline.csv', test_ans)\n",
    "\n",
    "print('Checking test error...')\n",
    "true_test_labels = np.loadtxt('test10D_correct_ans.csv')\n",
    "test_errors = (true_test_labels != test_ans).sum()\n",
    "print('Test errors=',test_errors,' -> ',test_errors/float(test_data.shape[0]),'%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Task 2 - Batch version of Perceptron learning\n",
    "\n",
    "Expected test output:\n",
    "\n",
    "`\n",
    "Loading train data...\n",
    "Train data:\n",
    "Number of examples= 500\n",
    "Number of inputs= 10\n",
    "Initial number of errors= 271\n",
    "Training...\n",
    "End of training\n",
    "Errors for train data after training= 0\n",
    "Loading test data...\n",
    "Test data:\n",
    "Number of examples= 439\n",
    "Number of inputs= 10\n",
    "Calculating answers for test data...\n",
    "Saving classifications for test data...\n",
    "Checking test error...\n",
    "Test errors= 0  ->  0.0 %\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data...\n",
      "Train data:\n",
      "Number of examples= 500\n",
      "Number of inputs= 10\n",
      "Initial number of errors= 229\n",
      "Training...\n",
      "End of training\n",
      "Errors for train data after training= 0\n",
      "Loading test data...\n",
      "Test data:\n",
      "Number of examples= 439\n",
      "Number of inputs= 10\n",
      "Calculating answers for test data...\n",
      "Saving classifications for test data...\n",
      "Checking test error...\n",
      "Test errors= 1  ->  0.002277904328018223 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import random\n",
    "\n",
    "class PerceptronBatch:\n",
    "    \"\"\"\n",
    "    This is a perceptron which can process all examples at a time.\n",
    "    Assumption: class label is given as {-1, 1}\n",
    "    \"\"\"\n",
    "    def __init__(self, num_of_inputs):\n",
    "        \"\"\"Perceptron constructor\"\"\"\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.input_num = num_of_inputs\n",
    "        self.InitWeights()\n",
    "        \n",
    "    def InitWeights(self):\n",
    "        \"\"\"Initializes weights to random values\"\"\"\n",
    "        self.w = -1 + 2*np.random.random_sample(self.input_num,)\n",
    "        self.b = random.random()\n",
    "        \n",
    "    def Forward(self, X): \n",
    "        \"\"\"\n",
    "        Forward pass - calculate the output as a vector of {-1, 1} of the neuron for all examples in X\n",
    "        X: matrix with examples as rows\n",
    "        \"\"\"\n",
    "        y = np.dot(X, self.w) + self.b\n",
    "        \n",
    "        y[y>0] = 1\n",
    "        y[y<0] = -1\n",
    "        \n",
    "        return y\n",
    "        \n",
    "    def Update(self, X, D, eta):\n",
    "        \"\"\"Calculate the output for all examples in X (as rows), compare with D and update the weights if necessary\"\"\"\n",
    "        u = self.Forward(X)\n",
    "    \n",
    "        result = u!=D\n",
    "        \n",
    "        self.w += eta*(np.multiply(X[result], D[result, None])).sum(axis=0)\n",
    "        self.b += eta*(D[result, None]).sum()\n",
    "            \n",
    "    def Train(self, X, D, eta, epochs):\n",
    "        \"\"\"\n",
    "        Train for the maximum number of epochs or until the classification error is 0\n",
    "        X: matrix with examples, each examples as a row\n",
    "        D: vector of correct class labels for examples in rows of X\n",
    "        The update to the weights vector is done once per epoch, based on all examples\n",
    "        \"\"\"\n",
    "        while epochs>0 and self.errors!=0:\n",
    "            self.Update(X, D, eta)\n",
    "            epochs -= 1\n",
    "            \n",
    "    def CalculateErrors(self, X, D):\n",
    "        \"\"\"Calculates the number of errors - missclassifications\"\"\"\n",
    "        solution = self.Forward(X)\n",
    "        self.errors = np.sum(solution!=D)\n",
    "        return self.errors\n",
    "    \n",
    "##############################################################################\n",
    "#DO NOT CHANGE THE FOLLOWING CODE\n",
    "##############################################################################\n",
    "print('Loading train data...')\n",
    "train_data = np.loadtxt('train10D.csv')\n",
    "X = train_data[:,:-1]\n",
    "D = train_data[:,-1]\n",
    "num_of_inputs = X.shape[1]\n",
    "print('Train data:')\n",
    "print('Number of examples=',X.shape[0])\n",
    "print('Number of inputs=',num_of_inputs)\n",
    "\n",
    "perc = PerceptronBatch(num_of_inputs)\n",
    "perc.InitWeights()\n",
    "\n",
    "start_errors = perc.CalculateErrors(X,D)\n",
    "print('Initial number of errors=',start_errors)\n",
    "\n",
    "print('Training...')\n",
    "max_epochs = 100\n",
    "eta = 0.01\n",
    "perc.Train(X, D, eta, max_epochs)\n",
    "print('End of training')\n",
    "\n",
    "train_errors = perc.CalculateErrors(X,D)\n",
    "print('Errors for train data after training=',train_errors)\n",
    "\n",
    "print('Loading test data...')\n",
    "test_data = np.loadtxt('test10D.csv')\n",
    "print('Test data:')\n",
    "print('Number of examples=',test_data.shape[0])\n",
    "print('Number of inputs=',test_data.shape[1])\n",
    "\n",
    "print('Calculating answers for test data...')\n",
    "test_ans = perc.Forward(test_data)\n",
    "print('Saving classifications for test data...')\n",
    "np.savetxt('test_data_classifications_percbatch.csv', test_ans)\n",
    "\n",
    "print('Checking test error...')\n",
    "true_test_labels = np.loadtxt('test10D_correct_ans.csv')\n",
    "test_errors = (true_test_labels != test_ans).sum()\n",
    "print('Test errors=',test_errors,' -> ',test_errors/float(test_data.shape[0]),'%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Online version of Widrow-Hoff learning\n",
    "\n",
    "Expected test output:\n",
    "\n",
    "---CLASSIFICATION PROBLEM---\n",
    "\n",
    "Loading train data...\n",
    "\n",
    "Train data:\n",
    "\n",
    "Number of examples= 500\n",
    "\n",
    "Number of inputs= 10\n",
    "\n",
    "Initial number of errors= 241\n",
    "\n",
    "Initial MSE= 1.5702372419231343\n",
    "\n",
    "Training...\n",
    "\n",
    "End of training\n",
    "\n",
    "Errors for train data after training= 6\n",
    "\n",
    "MSE for train data after training= 0.31192984053640277\n",
    "\n",
    "Loading test data...\n",
    "\n",
    "Test data:\n",
    "\n",
    "Number of examples= 439\n",
    "\n",
    "Number of inputs= 10\n",
    "\n",
    "Calculating answers for test data...\n",
    "\n",
    "Saving classifications for test data...\n",
    "\n",
    "Checking test error...\n",
    "\n",
    "Test errors= 6  ->  0.01366742596810934 %\n",
    "\n",
    "\n",
    "---REGRESSION PROBLEM---\n",
    "\n",
    "x= [-6.  -5.5 -5.  -4.5 -4.  -3.5 -3.  -2.5 -2.  -1.5 -1.  -0.5  0.   0.5\n",
    "  1.   1.5  2.   2.5  3.   3.5  4.   4.5  5.   5.5]\n",
    "\n",
    "Initial MSE= 7.177903123126157\n",
    "\n",
    "Training for regression...\n",
    "\n",
    "After training, training MSE= 0.04428786345738948\n",
    "\n",
    "After training, testing MSE= 0.005203074366538246\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CLASSIFICATION PROBLEM---\n",
      "Loading train data...\n",
      "Train data:\n",
      "Number of examples= 500\n",
      "Number of inputs= 10\n",
      "Initial number of errors= 205\n",
      "Initial MSE= 0.06645373008824731\n",
      "Training...\n",
      "End of training\n",
      "Errors for train data after training= 6\n",
      "MSE for train data after training= 0.02497718320933732\n",
      "Loading test data...\n",
      "Test data:\n",
      "Number of examples= 439\n",
      "Number of inputs= 10\n",
      "Calculating answers for test data...\n",
      "Saving classifications for test data...\n",
      "Checking test error...\n",
      "Test errors= 6  ->  0.01366742596810934 %\n",
      "\n",
      "---REGRESSION PROBLEM---\n",
      "x= [-6.  -5.5 -5.  -4.5 -4.  -3.5 -3.  -2.5 -2.  -1.5 -1.  -0.5  0.   0.5\n",
      "  1.   1.5  2.   2.5  3.   3.5  4.   4.5  5.   5.5]\n",
      "Initial MSE= 1.0810289588055786\n",
      "Training for regression...\n",
      "After training, training MSE= 0.0322178091042909\n",
      "After training, testing MSE= 0.012058634977381393\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import random\n",
    "\n",
    "class WidrowHoffOnline:\n",
    "    \"\"\"\n",
    "    This is a Widrow-Hoff model which can process one example at a time.\n",
    "    Can be used for both classification and regression problems\n",
    "    Assumption: class label is given as {-1, 1} in classification problems\n",
    "    \"\"\"\n",
    "    def __init__(self, num_of_inputs):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.input_num = num_of_inputs\n",
    "        self.InitWeights()\n",
    "        \n",
    "    def InitWeights(self):\n",
    "        \"\"\"Initializes weights to random values\"\"\"\n",
    "        self.w = -1 + 2*np.random.random_sample(self.input_num,)\n",
    "        self.b = random.random()\n",
    "        \n",
    "    def Forward(self, x): \n",
    "        \"\"\"Forward pass - calculate the output as a real value of the neuron for one example x\"\"\"\n",
    "        y = np.dot(x, self.w) + self.b\n",
    "        return y\n",
    "    \n",
    "    def ForwardClassify(self, x): \n",
    "        \"\"\"\n",
    "        Forward pass - calculate the output as {-1, 1} by comparing the real output value of the neuron with threshold 0; \n",
    "        for one example x\n",
    "        \"\"\"\n",
    "        y = np.dot(x, self.w) + self.b\n",
    "        return 1 if y > 0 else -1\n",
    "    \n",
    "    def Update(self, x, d, eta):\n",
    "        \"\"\"Calculate the output for x (one example), and update the weights\"\"\"\n",
    "        y = self.Forward(x)\n",
    "        \n",
    "        self.w += eta*np.multiply((d-y), x)\n",
    "        self.b += eta*1*(d-y)\n",
    "        \n",
    "        return y\n",
    "           \n",
    "    def Train(self, X, D, eta, epochs):\n",
    "        \"\"\"\n",
    "        Train for the maximum number of epochs\n",
    "        X: matrix with examples, each examples as a row\n",
    "        D: vector of real values required for examples in rows of X \n",
    "        \"\"\"\n",
    "        for i in range(epochs):\n",
    "            for j in range(len(X)):\n",
    "                self.Update(X[j], D[j], eta)\n",
    "        \n",
    "    def CalculateErrors(self, X, D):\n",
    "        \"\"\"\n",
    "        Calculates the number of errors - missclassifications;\n",
    "        D - assumed to be {-1, 1} here\n",
    "        \"\"\"\n",
    "        solution = 0\n",
    "        self.errors = 0\n",
    "        for i in range(len(D)):\n",
    "            solution = self.ForwardClassify(X[i])\n",
    "            if solution!=D[i]:\n",
    "                self.errors += 1\n",
    "        return self.errors\n",
    "        \n",
    "    def CalculateMSE(self, X, D):\n",
    "        \"\"\"\n",
    "        Calculates the mean square error \n",
    "        D - assumed to be a vector of any real values here\n",
    "        \"\"\"\n",
    "        Y = []\n",
    "        for i in range(len(D)):\n",
    "            Y.append(self.Forward(X[i]))\n",
    "        mse = np.sqrt(((Y - D) * (Y - D)).sum()) / D.shape[0]\n",
    "        return mse\n",
    "    \n",
    "##############################################################################\n",
    "#DO NOT CHANGE THE FOLLOWING CODE\n",
    "############################################################################## \n",
    "print('---CLASSIFICATION PROBLEM---')\n",
    "print('Loading train data...')\n",
    "train_data = np.loadtxt('train10D.csv')\n",
    "X = train_data[:,:-1]\n",
    "D = train_data[:,-1]\n",
    "num_of_inputs = X.shape[1]\n",
    "print('Train data:')\n",
    "print('Number of examples=',X.shape[0])\n",
    "print('Number of inputs=',num_of_inputs)\n",
    "\n",
    "perc = WidrowHoffOnline(num_of_inputs)\n",
    "perc.InitWeights()\n",
    "\n",
    "start_errors = perc.CalculateErrors(X,D)\n",
    "start_mse = perc.CalculateMSE(X,D)\n",
    "print('Initial number of errors=',start_errors)\n",
    "print('Initial MSE=',start_mse)\n",
    "\n",
    "print('Training...')\n",
    "max_epochs = 200\n",
    "eta = 0.001\n",
    "perc.Train(X, D, eta, max_epochs)\n",
    "print('End of training')\n",
    "\n",
    "train_errors = perc.CalculateErrors(X,D)\n",
    "train_mse = perc.CalculateMSE(X,D)\n",
    "print('Errors for train data after training=',train_errors)\n",
    "print('MSE for train data after training=',train_mse)\n",
    "\n",
    "print('Loading test data...')\n",
    "test_data = np.loadtxt('test10D.csv')\n",
    "print('Test data:')\n",
    "print('Number of examples=',test_data.shape[0])\n",
    "print('Number of inputs=',test_data.shape[1])\n",
    "\n",
    "print('Calculating answers for test data...')\n",
    "test_ans = []\n",
    "for x in test_data:\n",
    "    test_ans.append ( perc.ForwardClassify(x) )\n",
    "test_ans = np.array(test_ans)\n",
    "print('Saving classifications for test data...')\n",
    "np.savetxt('test_data_classifications_whonline.csv', test_ans)\n",
    "\n",
    "print('Checking test error...')\n",
    "true_test_labels = np.loadtxt('test10D_correct_ans.csv')\n",
    "test_errors = (true_test_labels != test_ans).sum()\n",
    "print('Test errors=',test_errors,' -> ',test_errors/float(test_data.shape[0]),'%')\n",
    "\n",
    "\n",
    "print()\n",
    "print('---REGRESSION PROBLEM---')\n",
    "xmin = -6\n",
    "xmax = 6\n",
    "x = np.arange(xmin, xmax, 0.5)\n",
    "print ('x=',x)\n",
    "\n",
    "#real values of unknown process\n",
    "a = 0.6\n",
    "b = -0.4\n",
    "d = a*x + b\n",
    "\n",
    "#training data with noise (e.g., measurement errors)\n",
    "sigma = 0.2\n",
    "tr_d = d + np.random.randn(len(d)) * sigma\n",
    "\n",
    "x.shape = (x.shape[0], 1)\n",
    "\n",
    "perc_reg = WidrowHoffOnline(1)\n",
    "start_mse = perc_reg.CalculateMSE(x, tr_d)\n",
    "print('Initial MSE=', start_mse)\n",
    "\n",
    "print('Training for regression...')\n",
    "eta = 0.01\n",
    "max_epochs = 100\n",
    "perc_reg.Train(x, tr_d, eta, max_epochs)\n",
    "\n",
    "train_mse = perc_reg.CalculateMSE(x, tr_d)\n",
    "print('After training, training MSE=', train_mse)\n",
    "\n",
    "#test data \n",
    "x_test = np.arange(xmin, xmax, 0.3)\n",
    "d_test = a*x_test + b\n",
    "x_test.shape = (x_test.shape[0],1)\n",
    "\n",
    "test_mse = perc_reg.CalculateMSE(x_test, d_test)\n",
    "print('After training, testing MSE=', test_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 - Batch version of Widrow-Hoff learning\n",
    "\n",
    "Expected test output:\n",
    "\n",
    "---CLASSIFICATION PROBLEM---\n",
    "\n",
    "Loading train data...\n",
    "\n",
    "Train data:\n",
    "\n",
    "Number of examples= 500\n",
    "\n",
    "Number of inputs= 10\n",
    "\n",
    "Initial number of errors= 320\n",
    "\n",
    "Initial MSE= 3.519674085434046\n",
    "\n",
    "Training...\n",
    "\n",
    "End of training\n",
    "\n",
    "Errors for train data after training= 6\n",
    "\n",
    "MSE for train data after training= 0.3119085202726676\n",
    "\n",
    "Loading test data...\n",
    "\n",
    "Test data:\n",
    "\n",
    "Number of examples= 439\n",
    "\n",
    "Number of inputs= 10\n",
    "\n",
    "Calculating answers for test data...\n",
    "\n",
    "Saving classifications for test data...\n",
    "\n",
    "Checking test error...\n",
    "\n",
    "Test errors= 6  ->  0.01366742596810934 %\n",
    "\n",
    "\n",
    "---REGRESSION PROBLEM---\n",
    "\n",
    "Initial MSE= 13.232938807228429\n",
    "\n",
    "Training for regression...\n",
    "\n",
    "After training, training MSE= 0.033557507870294406\n",
    "\n",
    "After training, testing MSE= 0.0035392872344154926\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CLASSIFICATION PROBLEM---\n",
      "Loading train data...\n",
      "Train data:\n",
      "Number of examples= 500\n",
      "Number of inputs= 10\n",
      "Initial number of errors= 185\n",
      "Initial MSE= 0.05666872076129856\n",
      "Training...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (500,) (10,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-3edeab15c3c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[0meta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m \u001b[0mperc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'End of training'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-3edeab15c3c1>\u001b[0m in \u001b[0;36mTrain\u001b[1;34m(self, X, D, eta, epochs)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \"\"\"\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUpdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mCalculateErrors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-3edeab15c3c1>\u001b[0m in \u001b[0;36mUpdate\u001b[1;34m(self, X, D, eta)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (500,) (10,) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import random\n",
    "\n",
    "class WidrowHoffBatch:\n",
    "    \"\"\"\n",
    "    This is a WidrowHoff model which can process all examples at a time.\n",
    "    Can be used for both classification and regression problems\n",
    "    Assumption: class label is given as {-1, 1} in classification problems\n",
    "    \"\"\"\n",
    "    def __init__(self, num_of_inputs):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.input_num = num_of_inputs\n",
    "        self.InitWeights()\n",
    "        \n",
    "    def InitWeights(self):\n",
    "        \"\"\"Initializes weights to random values\"\"\"\n",
    "        self.w = -1 + 2*np.random.random_sample(self.input_num,)\n",
    "        self.b = random.random()\n",
    "        \n",
    "    def Forward(self, X): \n",
    "        \"\"\"\n",
    "        Forward pass - calculate the output as a vector of real values of the neuron for all examples in X\n",
    "        X: matrix with examples as rows\n",
    "        \"\"\"\n",
    "        y = np.dot(X, self.w) + self.b\n",
    "        return y\n",
    "    \n",
    "    def ForwardClassify(self, X): \n",
    "        \"\"\"\n",
    "        Forward pass - calculate the output as a vector of {-1, 1} by comparing the real output values of the neuron with threshold 0; \n",
    "        X: matrix with examples as rows\n",
    "        \"\"\"\n",
    "        y = np.dot(X, self.w) + self.b\n",
    "        y[y>0] = 1\n",
    "        y[y<0] = -1\n",
    "        return y\n",
    "    \n",
    "    def Update(self, X, D, eta):\n",
    "        \"\"\"Calculate the output for all examples in X (as rows), and update the weights \"\"\"\n",
    "        y = self.Forward(X)\n",
    "                    \n",
    "        #for i in range(len(X)):\n",
    "        #    self.w += eta*np.multiply((D[i]-y[i]),X[i])\n",
    "        #    self.b += eta*(D[i]-y[i])\n",
    "        \n",
    "        delta = D - y\n",
    "        \n",
    "        self.w = eta*np.multiply(delta,X)\n",
    "        self.b = eta*delta\n",
    "        \n",
    "        return y\n",
    "        \n",
    "    def Train(self, X, D, eta, epochs):\n",
    "        \"\"\"\n",
    "        Train for the maximum number of epochs\n",
    "        X: matrix with examples, each examples as a row\n",
    "        D: vector of real values required for examples in rows of X \n",
    "        \"\"\"\n",
    "        for i in range(epochs):\n",
    "            self.Update(X, D, eta)\n",
    "        \n",
    "    def CalculateErrors(self, X, D):\n",
    "        \"\"\"\n",
    "        Calculates the number of errors - missclassifications\n",
    "        D - assumed to be {-1, 1} here\n",
    "        \"\"\"\n",
    "        solution = self.ForwardClassify(X)\n",
    "        self.errors = np.sum(solution!=D)\n",
    "        return self.errors\n",
    "    \n",
    "    def CalculateMSE(self, X, D):\n",
    "        \"\"\"\n",
    "        Calculates the mean square error \n",
    "        D - assumed to be a vector of any real values here\n",
    "        \"\"\"\n",
    "        Y = self.Forward(X)\n",
    "        mse = np.sqrt(((Y - D) * (Y - D)).sum()) / D.shape[0]\n",
    "        return mse\n",
    "    \n",
    "##############################################################################\n",
    "#DO NOT CHANGE THE FOLLOWING CODE\n",
    "##############################################################################     \n",
    "print('---CLASSIFICATION PROBLEM---')\n",
    "print('Loading train data...')\n",
    "train_data = np.loadtxt('train10D.csv')\n",
    "X = train_data[:,:-1]\n",
    "D = train_data[:,-1]\n",
    "num_of_inputs = X.shape[1]\n",
    "print('Train data:')\n",
    "print('Number of examples=',X.shape[0])\n",
    "print('Number of inputs=',num_of_inputs)\n",
    "\n",
    "perc = WidrowHoffBatch(num_of_inputs)\n",
    "perc.InitWeights()\n",
    "\n",
    "start_errors = perc.CalculateErrors(X,D)\n",
    "start_mse = perc.CalculateMSE(X,D)\n",
    "print('Initial number of errors=',start_errors)\n",
    "print('Initial MSE=',start_mse)\n",
    "\n",
    "print('Training...')\n",
    "max_epochs = 100\n",
    "eta = 0.001\n",
    "perc.Train(X, D, eta, max_epochs)\n",
    "print('End of training')\n",
    "\n",
    "train_errors = perc.CalculateErrors(X,D)\n",
    "train_mse = perc.CalculateMSE(X,D)\n",
    "print('Errors for train data after training=',train_errors)\n",
    "print('MSE for train data after training=',train_mse)\n",
    "\n",
    "print('Loading test data...')\n",
    "test_data = np.loadtxt('test10D.csv')\n",
    "print('Test data:')\n",
    "print('Number of examples=',test_data.shape[0])\n",
    "print('Number of inputs=',test_data.shape[1])\n",
    "\n",
    "print('Calculating answers for test data...')\n",
    "test_ans = perc.ForwardClassify(test_data)\n",
    "print('Saving classifications for test data...')\n",
    "np.savetxt('test_data_classifications_whbatch.csv', test_ans)\n",
    "\n",
    "print('Checking test error...')\n",
    "true_test_labels = np.loadtxt('test10D_correct_ans.csv')\n",
    "test_errors = (true_test_labels != test_ans).sum()\n",
    "print('Test errors=',test_errors,' -> ',test_errors/float(test_data.shape[0]),'%')\n",
    "\n",
    "print()\n",
    "print('---REGRESSION PROBLEM---')\n",
    "xmin = -6\n",
    "xmax = 6\n",
    "x = np.arange(xmin, xmax, 0.5)\n",
    "\n",
    "#real values of unknown process\n",
    "a = 0.6\n",
    "b = -0.4\n",
    "d = a*x + b\n",
    "\n",
    "#training data with noise (e.g., measurement errors)\n",
    "sigma = 0.2\n",
    "tr_d = d + np.random.randn(len(d)) * sigma\n",
    "\n",
    "x.shape = (x.shape[0], 1)\n",
    "\n",
    "perc_reg = WidrowHoffBatch(1)\n",
    "start_mse = perc_reg.CalculateMSE(x, tr_d)\n",
    "print('Initial MSE=', start_mse)\n",
    "\n",
    "print('Training for regression...')\n",
    "eta = 0.001\n",
    "max_epochs = 100\n",
    "perc_reg.Train(x, tr_d, eta, max_epochs)\n",
    "\n",
    "train_mse = perc_reg.CalculateMSE(x, tr_d)\n",
    "print('After training, training MSE=', train_mse)\n",
    "\n",
    "#test data \n",
    "x_test = np.arange(xmin, xmax, 0.3)\n",
    "d_test = a*x_test + b\n",
    "x_test.shape = (x_test.shape[0],1)\n",
    "\n",
    "test_mse = perc_reg.CalculateMSE(x_test, d_test)\n",
    "print('After training, testing MSE=', test_mse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
